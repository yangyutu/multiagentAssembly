/home/yangyutu/anaconda3/bin/python /home/yangyutu/Dropbox/TwoDColloidalTransformer/MultiagentAssemblyModel/GoalSelectionTrain/FreeSpace/MLP/DDPGHER_MLP.py
episode index:0
target Thresh 9.600000000000001
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7.51692  , 2.7069063], dtype=float32)}
done in step count: 17
reward sum = 0.16677181699666577
running average episode reward sum: 0.16677181699666577
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.9026833, -1.2035682], dtype=float32)}
episode index:1
target Thresh 9.822883724018634
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.6413918, 4.9070854], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22460067673883294
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.9361421, -0.5612912], dtype=float32)}
episode index:2
target Thresh 10.043549717928684
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8.529432 , 0.9803457], dtype=float32)}
done in step count: 199
reward sum = -1.2157665388506165
running average episode reward sum: -0.2555217284576502
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-368.028  ,  384.07013], dtype=float32)}
episode index:3
target Thresh 10.262020048513417
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 9.], dtype=float32)}
done in step count: 199
reward sum = -3.874204882944925
running average episode reward sum: -1.160192517079469
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-396.,   59.], dtype=float32)}
episode index:4
target Thresh 10.478316562987963
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: -0.7481540136635751
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:5
target Thresh 10.692460891184009
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 4.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.4884616780529793
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:6
target Thresh 10.904474447712829
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 5.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.7454927581084144
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-397., -393.], dtype=float32)}
episode index:7
target Thresh 11.114378434106762
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.5611811633448626
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:8
target Thresh 11.32219384093936
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 5.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.7530142827999917
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-396., -393.], dtype=float32)}
episode index:9
target Thresh 11.52794144992449
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: -0.5877128545199926
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:10
target Thresh 11.731641835994509
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 8.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.7214581690083036
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-394., -390.], dtype=float32)}
episode index:11
target Thresh 11.933315369357768
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 1.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.8519765914610303
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-394., -397.], dtype=float32)}
episode index:12
target Thresh 12.132982217535673
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., 10.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.9819680706774067
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398., -388.], dtype=float32)}
episode index:13
target Thresh 12.330662347379427
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 3.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -1.0588925880498359
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-392., -395.], dtype=float32)}
episode index:14
target Thresh 12.526375527066751
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 4.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.9342997488465135
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  0.], dtype=float32)}
episode index:15
target Thresh 12.720141328078707
target distance 2.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.8134060145436064
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:16
target Thresh 12.911979127156869
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 10.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.8745597890879099
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-392., -388.], dtype=float32)}
episode index:17
target Thresh 13.101908108241005
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., 11.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.9671879019871328
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398., -387.], dtype=float32)}
episode index:18
target Thresh 13.289947264387507
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 8.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -1.0246470289294634
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-395., -390.], dtype=float32)}
episode index:19
target Thresh 13.476115399668686
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.9329146774829903
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:20
target Thresh 13.660431131053208
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 4.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.9974272756238491
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-396., -394.], dtype=float32)}
episode index:21
target Thresh 13.842912890267812
target distance 2.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.906635126731856
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:22
target Thresh 14.023578925640482
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 10.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.947782303039026
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-392., -388.], dtype=float32)}
episode index:23
target Thresh 14.202447303925318
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.8809538737457333
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:24
target Thresh 14.379535912109205
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  9.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.8220961187959039
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., -1.], dtype=float32)}
episode index:25
target Thresh 14.554862459200532
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.7624385757652923
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., -1.], dtype=float32)}
episode index:26
target Thresh 14.728444478000117
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2., 12.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.8189289706792083
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-396., -386.], dtype=float32)}
episode index:27
target Thresh 14.90029932685449
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  9.], dtype=float32)}
done in step count: 199
reward sum = -1.5009463459149153
running average episode reward sum: -0.8432867340804836
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-386., -389.], dtype=float32)}
episode index:28
target Thresh 15.07044419139175
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., 10.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.8930933721618817
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-397., -388.], dtype=float32)}
episode index:29
target Thresh 15.238896086240139
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 1.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: -0.833323593089819
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., -1.], dtype=float32)}
episode index:30
target Thresh 15.40567185672952
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.7852776707320829
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:31
target Thresh 15.57078818057592
target distance 3.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.7294877435217053
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:32
target Thresh 15.734261569549325
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 9.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.7697733062601814
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-394., -389.], dtype=float32)}
episode index:33
target Thresh 15.896108371124853
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 8.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.8144175983831473
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-396., -390.], dtype=float32)}
episode index:34
target Thresh 16.056344770117544
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 3.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.8499745616833836
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-390., -395.], dtype=float32)}
episode index:35
target Thresh 16.21498679030082
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 14.], dtype=float32)}
done in step count: 199
reward sum = -1.5009463459149153
running average episode reward sum: -0.8680571112453705
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-388., -384.], dtype=float32)}
episode index:36
target Thresh 16.372050296008908
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.8302328379684686
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:37
target Thresh 16.527550993723256
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 13.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.7957978448640353
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., -1.], dtype=float32)}
episode index:38
target Thresh 16.68150443364323
target distance 3.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.749751746277778
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:39
target Thresh 16.83392601124111
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.7146054526208336
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:40
target Thresh 16.98483096880168
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 9.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.7423716655275637
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-393., -389.], dtype=float32)}
episode index:41
target Thresh 17.134234396946447
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  2.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.7791647029778842
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-387., -396.], dtype=float32)}
episode index:42
target Thresh 17.28215123614273
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  4.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.8089262520688965
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-388., -394.], dtype=float32)}
episode index:43
target Thresh 17.42859627819771
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  5.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.8326556595627117
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-383., -393.], dtype=float32)}
episode index:44
target Thresh 17.573584167737636
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.7961522004613181
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:45
target Thresh 17.717129403672278
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 11.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.767291478712159
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., -1.], dtype=float32)}
episode index:46
target Thresh 17.85924634064486
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 5.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.8050483796177283
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398., -393.], dtype=float32)}
episode index:47
target Thresh 17.999949190467504
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.7783120196256924
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0000002], dtype=float32)}
episode index:48
target Thresh 18.139252023542447
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 0.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.8143029135368808
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-389.     ,  184.38762], dtype=float32)}
episode index:49
target Thresh 18.27716877026908
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 12.], dtype=float32)}
done in step count: 199
reward sum = -1.667718162911581
running average episode reward sum: -0.8313712185243749
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-390.    ,  349.3697], dtype=float32)}
episode index:50
target Thresh 18.41371322243701
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 6.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.8554406321590227
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-394.     ,  389.62433], dtype=float32)}
episode index:51
target Thresh 18.548899034605245
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  0.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.830711635194426
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.        , -0.22536027], dtype=float32)}
episode index:52
target Thresh 18.68273972546765
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.8038965100020784
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000000e+00,  4.7683716e-07], dtype=float32)}
episode index:53
target Thresh 18.815248679204842
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  8.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.7801521875946326
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.6438159], dtype=float32)}
episode index:54
target Thresh 18.946439146822634
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.7527130569110938
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:55
target Thresh 19.0763242474771
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 13.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.7323535293055385
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -0.9953605], dtype=float32)}
episode index:56
target Thresh 19.204916969786545
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 2.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.7052946954580729
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2.3841858e-07, -1.9997203e+00], dtype=float32)}
episode index:57
target Thresh 19.33223017313037
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 7.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.7369597148686909
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398.,  397.], dtype=float32)}
episode index:58
target Thresh 19.458276588934993
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 12.], dtype=float32)}
done in step count: 199
reward sum = -1.667718162911581
running average episode reward sum: -0.7527352817846722
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-390.     ,  389.86502], dtype=float32)}
episode index:59
target Thresh 19.58306882194704
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  7.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.7337326856049277
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999999 , -0.03147531], dtype=float32)}
episode index:60
target Thresh 19.70661935149381
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 5.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.7120241169884534
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999965, -0.9805733], dtype=float32)}
episode index:61
target Thresh 19.828940532731202
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.6899575989725106
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:62
target Thresh 19.95004459787929
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.6674344624808835
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:63
target Thresh 20.069943657445506
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 6.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.6467542365046196
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.9999987], dtype=float32)}
episode index:64
target Thresh 20.188649701435715
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.6308438561122408
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:65
target Thresh 20.30617460055324
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.6154156084590251
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999999 , -0.07258451], dtype=float32)}
episode index:66
target Thresh 20.42253010738594
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 17.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.6338873185088421
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-392.    ,  391.0002], dtype=float32)}
episode index:67
target Thresh 20.53772785758145
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 14.], dtype=float32)}
done in step count: 199
reward sum = -1.667718162911581
running average episode reward sum: -0.6490907132794707
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-391.     ,  388.88727], dtype=float32)}
episode index:68
target Thresh 20.651779371010797
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 13.], dtype=float32)}
done in step count: 199
reward sum = -1.667718162911581
running average episode reward sum: -0.6638534299408057
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-390.     ,  387.12637], dtype=float32)}
episode index:69
target Thresh 20.764696052920357
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  6.], dtype=float32)}
done in step count: 199
reward sum = -1.2157665388506165
running average episode reward sum: -0.6717379029252315
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-385.     ,   48.08762], dtype=float32)}
episode index:70
target Thresh 20.876489195072427
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 18.], dtype=float32)}
done in step count: 199
reward sum = -1.0941898842600466
running average episode reward sum: -0.6776879308313556
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-383.     ,   79.06122], dtype=float32)}
episode index:71
target Thresh 20.987169976874384
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  3.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.661632585958698
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8.3446503e-07, 6.9945467e-01], dtype=float32)}
episode index:72
target Thresh 21.096749466496632
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 19.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.6779529639838769
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-393.     ,   35.90384], dtype=float32)}
episode index:73
target Thresh 21.20523862197947
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 8.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.6966145633069518
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-395.     ,   91.58707], dtype=float32)}
episode index:74
target Thresh 21.31264829232883
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  3.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.6815868063295257
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.16784728], dtype=float32)}
episode index:75
target Thresh 21.418989218601272
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  3.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.6648489536146635
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.78938043], dtype=float32)}
episode index:76
target Thresh 21.524272034978033
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 3.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.6456950711001872
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9999094], dtype=float32)}
episode index:77
target Thresh 21.62850726982849
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.6312849176245439
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:78
target Thresh 21.731705346762993
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.6183899124773977
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.24403584], dtype=float32)}
episode index:79
target Thresh 21.833876585675227
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 12.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.6052791984464302
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.0545435], dtype=float32)}
episode index:80
target Thresh 21.935031203774237
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 16.], dtype=float32)}
done in step count: 199
reward sum = -1.667718162911581
running average episode reward sum: -0.618395728871926
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-390.      ,   96.729164], dtype=float32)}
episode index:81
target Thresh 22.03517931660612
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  7.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.6036532199832438
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.1920929e-07, 9.9925935e-01], dtype=float32)}
episode index:82
target Thresh 22.134330939065617
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.5921793445605542
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.03562582], dtype=float32)}
episode index:83
target Thresh 22.232495986397602
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 12.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.5794355797443572
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.6765531], dtype=float32)}
episode index:84
target Thresh 22.329684275188615
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.5669916682179531
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:85
target Thresh 22.425905524348522
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 2.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.5899553211604645
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398.     ,  102.69124], dtype=float32)}
episode index:86
target Thresh 22.521169356082424
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 20.], dtype=float32)}
done in step count: 199
reward sum = -0.984770895128533
running average episode reward sum: -0.5944934312060745
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-381.     ,   98.74735], dtype=float32)}
episode index:87
target Thresh 22.61548529685289
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 10.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.5823026319878236
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.00969648], dtype=float32)}
episode index:88
target Thresh 22.708862778332577
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., 10.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.6043201959123865
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398.     ,   74.78879], dtype=float32)}
episode index:89
target Thresh 22.80131113834746
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 8.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.6181946401999907
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-393.      ,   66.070145], dtype=float32)}
episode index:90
target Thresh 22.89283962181058
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 19.], dtype=float32)}
done in step count: 199
reward sum = -1.3508517106179159
running average episode reward sum: -0.62624581679799
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-386.     ,   67.96627], dtype=float32)}
episode index:91
target Thresh 22.983457381646556
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.6115148840067075
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99255276], dtype=float32)}
episode index:92
target Thresh 23.073173479706885
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 18.], dtype=float32)}
done in step count: 199
reward sum = -1.3508517106179159
running average episode reward sum: -0.6194647423573657
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-386.     ,   92.90847], dtype=float32)}
episode index:93
target Thresh 23.161996887676136
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 10.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.6077864270131385
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.17645133], dtype=float32)}
episode index:94
target Thresh 23.249936487969126
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 16.], dtype=float32)}
done in step count: 199
reward sum = -1.5009463459149153
running average episode reward sum: -0.6171881103699993
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-389.      ,   89.007385], dtype=float32)}
episode index:95
target Thresh 23.337001074619174
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 21.], dtype=float32)}
done in step count: 199
reward sum = -0.984770895128533
running average episode reward sum: -0.621017097711234
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-380.99997,   80.46122], dtype=float32)}
episode index:96
target Thresh 23.42319935415749
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 3.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.6070993956729739
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000017 , 0.49492657], dtype=float32)}
episode index:97
target Thresh 23.508539946483864
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 16.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.597346560614066
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.68945444], dtype=float32)}
episode index:98
target Thresh 23.59303138572865
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.5864814751533179
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0000007], dtype=float32)}
episode index:99
target Thresh 23.676682121106175
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 18.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.5991468622197524
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-393.     ,   87.57317], dtype=float32)}
episode index:100
target Thresh 23.75950051775969
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., 11.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.6183817033985066
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398.     ,  100.42996], dtype=float32)}
episode index:101
target Thresh 23.84149485759788
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 9.], dtype=float32)}
done in step count: 199
reward sum = -2.541865821273924
running average episode reward sum: -0.6372393908286578
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-398.     ,  100.65064], dtype=float32)}
episode index:102
target Thresh 23.922673340123048
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 18.], dtype=float32)}
done in step count: 199
reward sum = -1.0941898842600466
running average episode reward sum: -0.6416758033862441
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-382.     ,   68.09736], dtype=float32)}
episode index:103
target Thresh 24.003044083251098
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 21.], dtype=float32)}
done in step count: 199
reward sum = -1.0941898842600466
running average episode reward sum: -0.6460269003177229
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-382.      ,   62.916912], dtype=float32)}
episode index:104
target Thresh 24.082615124123326
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 11.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.6368855908281257
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.     , 0.73769], dtype=float32)}
episode index:105
target Thresh 24.16139441991012
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.6246876135561622
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:106
target Thresh 24.239389848606713
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.       ,  1.0000001], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.6159166022510579
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.2480465], dtype=float32)}
episode index:107
target Thresh 24.31660920982097
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  8.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.6066264439987334
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.0000005 , -0.43248922], dtype=float32)}
episode index:108
target Thresh 24.393060225553363
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 10.], dtype=float32)}
done in step count: 199
reward sum = -1.667718162911581
running average episode reward sum: -0.616361230410778
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-391.      ,   60.422245], dtype=float32)}
episode index:109
target Thresh 24.468750540969175
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 3., 17.], dtype=float32)}
done in step count: 199
reward sum = -2.0589113138914144
running average episode reward sum: -0.6294753220787837
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-395.     ,   65.53529], dtype=float32)}
episode index:110
target Thresh 24.543687725163018
target distance 3.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0000015], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.614795364222218
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0000015], dtype=float32)}
episode index:111
target Thresh 24.617879271915765
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.      ,  4.602816], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.6061929195407697
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.08320603], dtype=float32)}
episode index:112
target Thresh 24.691332600443918
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., 18.], dtype=float32)}
done in step count: 199
reward sum = -2.2876792384410245
running average episode reward sum: -0.6210733294425419
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-397.      ,   42.857235], dtype=float32)}
episode index:113
target Thresh 24.764055056141537
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.       ,  3.9999652], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.61044558093866
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.5499383], dtype=float32)}
episode index:114
target Thresh 24.836053911314792
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 11.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.6212505774678608
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-392.      ,   39.400414], dtype=float32)}
episode index:115
target Thresh 24.907336365909206
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.       ,  7.9999557], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.612889120419862
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.23395312], dtype=float32)}
episode index:116
target Thresh 24.97790954822964
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 22.], dtype=float32)}
done in step count: 199
reward sum = -1.3508517106179159
running average episode reward sum: -0.6191964929856574
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-387.     ,   45.82199], dtype=float32)}
episode index:117
target Thresh 25.047780515653137
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.6103010378756094
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.000001], dtype=float32)}
episode index:118
target Thresh 25.11695625533466
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 19.], dtype=float32)}
done in step count: 199
reward sum = -1.5009463459149153
running average episode reward sum: -0.6177854522288808
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-389.     ,   37.31899], dtype=float32)}
episode index:119
target Thresh 25.185443684905827
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 12.], dtype=float32)}
done in step count: 199
reward sum = -1.853020181796765
running average episode reward sum: -0.6280790749752799
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-79.999985 ,  -6.1286573], dtype=float32)}
episode index:120
target Thresh 25.253249653166673
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 10.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.6205542104177899
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99992037,  0.10170448], dtype=float32)}
episode index:121
target Thresh 25.320380940770523
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.     , 11.99752], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.6119392807422342
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000001, 1.3892119], dtype=float32)}
episode index:122
target Thresh 25.38684426090208
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  6.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.6021634329313218
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.00206864, -0.13679934], dtype=float32)}
episode index:123
target Thresh 25.45264625994875
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.      ,  8.007403], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.5941829174318757
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.11181605], dtype=float32)}
episode index:124
target Thresh 25.517793518165266
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.       ,  7.8497515], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.5859857164124206
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 3.695488e-06, -3.955021e-01], dtype=float32)}
episode index:125
target Thresh 25.582292550331744
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7.      , 4.999932], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.5755493218377189
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.12915766], dtype=float32)}
episode index:126
target Thresh 25.646149806405145
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.5676279318232487
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.04631507,  1.0000012 ], dtype=float32)}
episode index:127
target Thresh 25.709371672164295
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.5604692882925982
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9833212 , 0.36738682], dtype=float32)}
episode index:128
target Thresh 25.771964469848452
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.5534216314833532
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9035801, 1.2227339], dtype=float32)}
episode index:129
target Thresh 25.83393445878955
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.5467506143481736
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.3591999, 1.0000035], dtype=float32)}
episode index:130
target Thresh 25.89528783603812
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 19.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.5401814448028441
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.99999094, -0.03335333], dtype=float32)}
episode index:131
target Thresh 25.956030736983017
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.5337118081294135
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.07523489, 0.00018275], dtype=float32)}
episode index:132
target Thresh 26.016169235964952
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 9.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.5252591629555082
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.0157356 , -0.97003114], dtype=float32)}
episode index:133
target Thresh 26.075709346883944
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 10.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.5173733408438999
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.6208026], dtype=float32)}
episode index:134
target Thresh 26.1346570238007
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8.       , 2.0006037], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.5086809457265377
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.4069697], dtype=float32)}
episode index:135
target Thresh 26.19301816153203
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 17.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.5020919645888425
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -0.806085], dtype=float32)}
episode index:136
target Thresh 26.250798596240347
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5.       , 2.0000606], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.492514650978705
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.2518943], dtype=float32)}
episode index:137
target Thresh 26.308004106017275
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.48613830938465646
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3.2146692e-02, 3.2544136e-05], dtype=float32)}
episode index:138
target Thresh 26.364640411461455
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.4803832812877165
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0002214e+00, 3.0970573e-04], dtype=float32)}
episode index:139
target Thresh 26.420713176250633
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.00364, 18.     ], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.4741846829285186
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0050364e+00, 8.0835819e-04], dtype=float32)}
episode index:140
target Thresh 26.476228007708016
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.46881862463483404
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00167358, 0.00020564], dtype=float32)}
episode index:141
target Thresh 26.53119045736301
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 24.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: -0.4637270386667514
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.4674863], dtype=float32)}
episode index:142
target Thresh 26.585606021506383
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 16.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.4577749580536972
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.9999981, -0.5623615], dtype=float32)}
episode index:143
target Thresh 26.6394801417399
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.       , 2.0000017], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.4489709652894354
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5678446], dtype=float32)}
episode index:144
target Thresh 26.692818205520474
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.      , 4.990567], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.4413497862184738
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000002 , 0.12839413], dtype=float32)}
episode index:145
target Thresh 26.745625546698932
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 3.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.43277889727177193
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.8437233], dtype=float32)}
episode index:146
target Thresh 26.7979074460534
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.      ,  5.999995], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.4265811027325082
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.3396287], dtype=float32)}
episode index:147
target Thresh 26.849669131817386
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 17.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.4213428625782345
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0956126], dtype=float32)}
episode index:148
target Thresh 26.900915780202595
target distance 2.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0425532e-01, 8.4638596e-06], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.4118036487354276
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0425532e-01, 8.4638596e-06], dtype=float32)}
episode index:149
target Thresh 26.95165251591657
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 18.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.40673376814319134
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.07903767, -1.5794016 ], dtype=float32)}
episode index:150
target Thresh 27.001884412675174
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.      ,  7.009619], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.4019619511615146
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.04442668], dtype=float32)}
episode index:151
target Thresh 27.05161649370993
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 21.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.3974593755849191
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.49147105], dtype=float32)}
episode index:152
target Thresh 27.10085373227039
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  4.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.3928105522406386
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.98939764], dtype=float32)}
episode index:153
target Thresh 27.14960105212144
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 18.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.38842587633984876
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.02421761, -1.5096704 ], dtype=float32)}
episode index:154
target Thresh 27.197863328035695
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 25.], dtype=float32)}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: -0.38444398085023934
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.6348572e-04, -1.3979818e+00], dtype=float32)}
episode index:155
target Thresh 27.245645386280955
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 25.], dtype=float32)}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: -0.38051313530280445
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9997733 , 0.89738023], dtype=float32)}
episode index:156
target Thresh 27.29295200510287
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  8.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.3753476553964171
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5967451], dtype=float32)}
episode index:157
target Thresh 27.33978791520274
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  4.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.37024756131162967
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.1710848], dtype=float32)}
episode index:158
target Thresh 27.38615780021061
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 13.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.36548235344803454
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2.3841858e-07, -1.2697958e+00], dtype=float32)}
episode index:159
target Thresh 27.432066297153618
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 19.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.3614329041359781
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.8683721], dtype=float32)}
episode index:160
target Thresh 27.47751799691972
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.       , 3.0001438], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.3551128239860652
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0394481], dtype=float32)}
episode index:161
target Thresh 27.52251744471676
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  8.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.35076843346701536
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.31358886], dtype=float32)}
episode index:162
target Thresh 27.567069140527032
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.3449938418506533
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.000000e+00, 9.524822e-05], dtype=float32)}
episode index:163
target Thresh 27.611177539557232
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.341168089543753
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.46828532, 1.0000006 ], dtype=float32)}
episode index:164
target Thresh 27.654847052684023
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.33649151197076055
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00389588, 1.0000012 ], dtype=float32)}
episode index:165
target Thresh 27.69808204689511
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 15.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.33257402939208125
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5122714], dtype=float32)}
episode index:166
target Thresh 27.74088684572594
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  7.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.32870346277242807
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.7225352], dtype=float32)}
episode index:167
target Thresh 27.783265729692072
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 13.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.32389988918449697
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.97141254], dtype=float32)}
episode index:168
target Thresh 27.825222936717218
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 22.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.32031214110363604
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.8985204], dtype=float32)}
episode index:169
target Thresh 27.86676266255704
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9.867453, 15.      ], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.3156144408618499
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.1066833, 1.0000119], dtype=float32)}
episode index:170
target Thresh 27.907889061218743
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.       ,  3.0098858], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.3103155844825408
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.9862804], dtype=float32)}
episode index:171
target Thresh 27.948606245376464
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.3064842238745028
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0042964e+00,  5.0127506e-04], dtype=float32)}
episode index:172
target Thresh 27.988918286782553
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.      ,  9.209191], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.3028987046839565
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4540666], dtype=float32)}
episode index:173
target Thresh 28.028829216674737
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.29915400844956597
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4290264], dtype=float32)}
episode index:174
target Thresh 28.06834302617927
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 18.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.2954521087435684
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.8552791], dtype=float32)}
episode index:175
target Thresh 28.10746366671003
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  7.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.2921686903047925
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.2249794], dtype=float32)}
episode index:176
target Thresh 28.14619505036367
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.28594174855165805
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99993813, 1.0000001 ], dtype=float32)}
episode index:177
target Thresh 28.18454105031083
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 22.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.28274865144473305
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.5976994], dtype=float32)}
episode index:178
target Thresh 28.222505501183463
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.2795912314004552
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.34260428, 1.        ], dtype=float32)}
episode index:179
target Thresh 28.26009219945829
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.2758856107315638
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.4139111e-01, 1.2516975e-05], dtype=float32)}
episode index:180
target Thresh 28.297304903836462
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.99673, 26.     ], dtype=float32)}
done in step count: 14
reward sum = -0.7712320754503899
running average episode reward sum: -0.2786223315311154
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.21901107, -1.0884957 ], dtype=float32)}
episode index:181
target Thresh 28.33414733561943
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.27517562399468065
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9278995,  1.       ], dtype=float32)}
episode index:182
target Thresh 28.370623179081072
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.       ,  3.0795145], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.27044521074880806
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.3165894], dtype=float32)}
episode index:183
target Thresh 28.40673608183613
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 15.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.26726990745077106
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4432571], dtype=float32)}
episode index:184
target Thresh 28.442489655204977
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.2626333674104966
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0670239e+00,  1.2516975e-05], dtype=float32)}
episode index:185
target Thresh 28.477887474574743
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.       ,  4.9997263], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.2595342063164079
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999985 , -0.45609725], dtype=float32)}
episode index:186
target Thresh 28.51293307975686
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.2546377667104378
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-6.0439110e-04,  4.7683716e-06], dtype=float32)}
episode index:187
target Thresh 28.547629975341057
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.       ,  2.0007963], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.2507391780577227
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.8914735], dtype=float32)}
episode index:188
target Thresh 28.5819816310458
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 11.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.24775214221567127
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999899 , -0.07708824], dtype=float32)}
episode index:189
target Thresh 28.615991482065294
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.24440912836716774
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000826e+00, 1.1563301e-05], dtype=float32)}
episode index:190
target Thresh 28.649662929412976
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 3.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.23888866172650194
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99957585], dtype=float32)}
episode index:191
target Thresh 28.68299934026164
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.23515332025917643
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9126775,  1.       ], dtype=float32)}
episode index:192
target Thresh 28.716004048280155
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 16.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.23247154379938278
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5158129], dtype=float32)}
episode index:193
target Thresh 28.74868035396683
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  4.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.2288077889344375
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4643799], dtype=float32)}
episode index:194
target Thresh 28.781031524979454
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  8.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.22618605906051223
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5641892], dtype=float32)}
episode index:195
target Thresh 28.813060796462096
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.      ,  3.984974], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.222591758248979
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.2541282], dtype=float32)}
episode index:196
target Thresh 28.84477137136859
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.21986890365842582
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.6379508,  1.       ], dtype=float32)}
episode index:197
target Thresh 28.87616642078286
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.21577618192277717
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9999995,  1.       ], dtype=float32)}
episode index:198
target Thresh 28.907249084236
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.      ,  4.999605], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.212745042872914
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.8566834], dtype=float32)}
episode index:199
target Thresh 28.938022470020265
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 18.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.21026916997614442
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.9347311], dtype=float32)}
episode index:200
target Thresh 28.968489655499877
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.20595887559815365
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9724749e+00, 7.0333481e-06], dtype=float32)}
episode index:201
target Thresh 28.99865368741877
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.20354111118192023
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.58144593, 1.        ], dtype=float32)}
episode index:202
target Thresh 29.028517582205275
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 14.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.20041791748151666
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.9805359], dtype=float32)}
episode index:203
target Thresh 29.058084326273754
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.      ,  5.999789], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.19789718947381316
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999976, -0.3493415], dtype=float32)}
episode index:204
target Thresh 29.08735687632326
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.19523096689052624
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-8.963717e-01,  4.887581e-06], dtype=float32)}
episode index:205
target Thresh 29.116338159633184
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.       ,  7.9989986], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.1929122265828975
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.9930629], dtype=float32)}
episode index:206
target Thresh 29.145031074356016
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.9940405, 21.       ], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.19029584655061296
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.309911, 1.      ], dtype=float32)}
episode index:207
target Thresh 29.173438489807133
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.1875183641681581
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999994 , -0.78020906], dtype=float32)}
episode index:208
target Thresh 29.201563246751753
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.18456149539223385
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8.4159708e-01, 1.0728836e-06], dtype=float32)}
episode index:209
target Thresh 29.22940815768901
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  7.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.18140502684274706
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.1959615], dtype=float32)}
episode index:210
target Thresh 29.256976007133204
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 19.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.17920675877012268
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.1455324], dtype=float32)}
episode index:211
target Thresh 29.28426955189225
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.       ,  1.8848695], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.1768812052094617
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9697905, -1.5544543], dtype=float32)}
episode index:212
target Thresh 29.31129152134337
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.17457748783246893
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.42749107, 1.        ], dtype=float32)}
episode index:213
target Thresh 29.338044617706025
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.17229530052442002
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:214
target Thresh 29.364531516312148
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.17003434286574828
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00544941, 1.        ], dtype=float32)}
episode index:215
target Thresh 29.390754865873667
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  4.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.1674535334589624
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999999, -0.9264997], dtype=float32)}
episode index:216
target Thresh 29.4167172887474
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.16538033958827136
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.39939332,  0.        ], dtype=float32)}
episode index:217
target Thresh 29.442421381197263
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.16318221603011415
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.4953817,  0.       ], dtype=float32)}
episode index:218
target Thresh 29.467869713653922
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.16084495276011362
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9.536743e-06, -1.000000e+00], dtype=float32)}
episode index:219
target Thresh 29.493064830971832
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.15883006871810856
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00534225, 1.        ], dtype=float32)}
episode index:220
target Thresh 29.518009252683722
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: -0.16148610196900898
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.5932808, 0.       ], dtype=float32)}
episode index:221
target Thresh 29.542705473252546
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  7.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.15948648197599094
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.5926833], dtype=float32)}
episode index:222
target Thresh 29.567155962320943
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.15750479579456947
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.734789,  0.      ], dtype=float32)}
episode index:223
target Thresh 29.591363164958192
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: -0.16013117356855397
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2325597, 0.       ], dtype=float32)}
episode index:224
target Thresh 29.61532950190474
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.15705751946380483
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.47531223, 1.        ], dtype=float32)}
episode index:225
target Thresh 29.63905736981424
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 17.], dtype=float32)}
done in step count: 15
reward sum = 0.20589113209464907
running average episode reward sum: -0.1554515519790329
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.2424839, -1.9763055], dtype=float32)}
episode index:226
target Thresh 29.662549141493262
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 19.], dtype=float32)}
done in step count: 16
reward sum = 0.18530201888518416
running average episode reward sum: -0.15395043492676766
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.26322365, -0.9922106 ], dtype=float32)}
episode index:227
target Thresh 29.685807166138556
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 16.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.15157600104989585
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.01311588, -1.9999992 ], dtype=float32)}
episode index:228
target Thresh 29.70883376957196
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 11.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.1485933940584116
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., -1.], dtype=float32)}
episode index:229
target Thresh 29.73163125447301
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.14626289891467936
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9984627, 0.       ], dtype=float32)}
episode index:230
target Thresh 29.754201900609196
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 11.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.1444070875060401
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.172113 , -1.8277197], dtype=float32)}
episode index:231
target Thresh 29.776547965063937
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.000003, 19.      ], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.14211472726247956
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.487442, 1.      ], dtype=float32)}
episode index:232
target Thresh 29.798671682462302
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.14000831881886375
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.18488133, 1.        ], dtype=float32)}
episode index:233
target Thresh 29.820575265194467
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 19.], dtype=float32)}
done in step count: 16
reward sum = 0.18530201888518416
running average episode reward sum: -0.1386181037004704
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.1873827, -0.9944756], dtype=float32)}
episode index:234
target Thresh 29.842260903636955
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.13619646406770244
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.84008706,  0.        ], dtype=float32)}
episode index:235
target Thresh 29.863730766371688
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 21.], dtype=float32)}
done in step count: 15
reward sum = 0.20589113209464907
running average episode reward sum: -0.13474694035515009
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.4983606 ,  0.75160205], dtype=float32)}
episode index:236
target Thresh 29.884987000402827
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 6.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.13254370225660517
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9967165, -0.965325 ], dtype=float32)}
episode index:237
target Thresh 29.906031731371492
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.999987, 24.      ], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.13080011721989254
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.335144e-05,  0.000000e+00], dtype=float32)}
episode index:238
target Thresh 29.92686706376831
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 7.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.1275076481101859
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.16609073, -1.        ], dtype=float32)}
episode index:239
target Thresh 29.94749508114389
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  3.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.1255235394093101
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.4742134, -1.9744215], dtype=float32)}
episode index:240
target Thresh 29.96791784631716
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.12197779858188558
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:241
target Thresh 29.988137401581653
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  1.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.12030669389154308
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999938 ,  0.44276893], dtype=float32)}
episode index:242
target Thresh 30.008155768909745
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  8.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.11852020298626924
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9992478, -1.8803762], dtype=float32)}
episode index:243
target Thresh 30.027974950154857
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.11534553002321075
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.6273656, 1.       ], dtype=float32)}
episode index:244
target Thresh 30.047596927251618
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.11345155463495275
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.340559, 1.      ], dtype=float32)}
episode index:245
target Thresh 30.0670236624141
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.11157297742058304
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.38063717, -1.        ], dtype=float32)}
episode index:246
target Thresh 30.086257098332005
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.10784191273466975
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:247
target Thresh 30.10529915836495
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.10476150179622351
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:248
target Thresh 30.12415174673481
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 18.], dtype=float32)}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: -0.10342202618840891
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9934592, -1.9472672], dtype=float32)}
episode index:249
target Thresh 30.142816748716132
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.10009233808365528
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:250
target Thresh 30.161296030824666
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  0.], dtype=float32)}
done in step count: 15
reward sum = 0.20589113209464907
running average episode reward sum: -0.09887328043354252
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9948621, -1.9793175], dtype=float32)}
episode index:251
target Thresh 30.179591441004025
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 15.], dtype=float32)}
done in step count: 24
reward sum = 0.07976644307687256
running average episode reward sum: -0.0981643926418345
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99961233, -1.9887532 ], dtype=float32)}
episode index:252
target Thresh 30.197704808810474
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.09489496816498931
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., -1.], dtype=float32)}
episode index:253
target Thresh 30.215637945595883
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 13.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: -0.09352063135003699
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.1266215, -1.0185938], dtype=float32)}
episode index:254
target Thresh 30.23339264468888
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 6.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.09058094259964469
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.9999994], dtype=float32)}
episode index:255
target Thresh 30.25097068157417
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 11.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.08912387041573593
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.8837   , -1.5141929], dtype=float32)}
episode index:256
target Thresh 30.268373814070085
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.08691600749583034
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.5073528,  1.       ], dtype=float32)}
episode index:257
target Thresh 30.28560378250438
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.08507749394352092
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999998, -1.832855 ], dtype=float32)}
episode index:258
target Thresh 30.302662309888262
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 12.], dtype=float32)}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: -0.08386573557096057
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99706364,  0.033705  ], dtype=float32)}
episode index:259
target Thresh 30.319551102088674
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 1.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.0812720596649184
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.8916225, -1.385046 ], dtype=float32)}
episode index:260
target Thresh 30.336271847998923
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: -0.08381819513427542
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.6598482, 0.       ], dtype=float32)}
episode index:261
target Thresh 30.35282621970752
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 21.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.08230052799219803
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0., -1.], dtype=float32)}
episode index:262
target Thresh 30.369215872665443
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 10.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.07996691001504139
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.33123136, -1.9999998 ], dtype=float32)}
episode index:263
target Thresh 30.385442445851638
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 0.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.07785227437104501
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9998324, -1.6675214], dtype=float32)}
episode index:264
target Thresh 30.401507561936953
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.07624272450511654
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9188237, 1.       ], dtype=float32)}
episode index:265
target Thresh 30.417412827446377
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  7.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.07395819922502211
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.5314465], dtype=float32)}
episode index:266
target Thresh 30.43315983291972
target distance 3.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.06993588387211941
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:267
target Thresh 30.448750153070648
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 15.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.06862108752751821
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.5585804], dtype=float32)}
episode index:268
target Thresh 30.464185346944173
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7.9999933, 16.       ], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.0667657406965609
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.01372218, 0.        ], dtype=float32)}
episode index:269
target Thresh 30.479466958072543
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.06408846017546252
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:270
target Thresh 30.494596514629606
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  5.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: -0.06291401352229513
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9649359, -1.5144025], dtype=float32)}
episode index:271
target Thresh 30.50957552958362
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.06092426751669846
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.9991083e-01, 2.3841858e-07], dtype=float32)}
episode index:272
target Thresh 30.524405500848573
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: -0.06343301898061934
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.3021977, 1.       ], dtype=float32)}
episode index:273
target Thresh 30.539087911433942
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.06080698606463168
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.9992013e-01, 2.3841858e-07], dtype=float32)}
episode index:274
target Thresh 30.553624229593026
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.05917706797348757
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9999998, -1.5793002], dtype=float32)}
episode index:275
target Thresh 30.568015908969752
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  0.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.057229698524308266
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.     , -1.99981], dtype=float32)}
episode index:276
target Thresh 30.582264388744047
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.05589020287588116
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.3901327,  1.       ], dtype=float32)}
episode index:277
target Thresh 30.59637109377577
target distance 3.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: -0.05209203667848591
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:278
target Thresh 30.610337434747173
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 0.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.05019100106315083
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9998207, -1.7036693], dtype=float32)}
episode index:279
target Thresh 30.624164808304
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  4.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: -0.04910393826352207
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.9996479], dtype=float32)}
episode index:280
target Thresh 30.63785459719512
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 3.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.047037942041943705
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9355394, -1.5962403], dtype=float32)}
episode index:281
target Thresh 30.651408170410832
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  2.], dtype=float32)}
done in step count: 72
reward sum = 0.0005075287860564165
running average episode reward sum: -0.04686934108156073
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9992182, -1.5799643], dtype=float32)}
episode index:282
target Thresh 30.66482688331976
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 15.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.04570574080748808
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9675133, -1.8934585], dtype=float32)}
episode index:283
target Thresh 30.678112077804368
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.04455033490154269
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., -1.], dtype=float32)}
episode index:284
target Thresh 30.69126508239518
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.04271578320013377
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:285
target Thresh 30.704287212403617
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  5.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.040894060531601835
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.7092724], dtype=float32)}
episode index:286
target Thresh 30.71717977005353
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.03889986171441855
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:287
target Thresh 30.72994404461143
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  3.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.037270114937632375
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9900736, -1.8188772], dtype=float32)}
episode index:288
target Thresh 30.742581312515405
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.03461866125272708
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:289
target Thresh 30.75509283750278
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 12.], dtype=float32)}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: -0.03371043164651212
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9996966, -1.4414222], dtype=float32)}
episode index:290
target Thresh 30.767479870736476
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.03195095628002926
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9896336,  0.       ], dtype=float32)}
episode index:291
target Thresh 30.779743650930147
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: -0.030021531772220944
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:292
target Thresh 30.791885404472026
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 4.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.02715456408699152
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.28887224,  0.        ], dtype=float32)}
episode index:293
target Thresh 30.803906345547585
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.025744444858804474
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0013325,  1.       ], dtype=float32)}
episode index:294
target Thresh 30.815807676260953
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 10.], dtype=float32)}
done in step count: 199
reward sum = 0.0
running average episode reward sum: -0.025657175554198358
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-4.0161304 ,  0.28343916], dtype=float32)}
episode index:295
target Thresh 30.827590586755115
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: -0.023107658069217957
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0003047, 0.       ], dtype=float32)}
episode index:296
target Thresh 30.83925625533094
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.02207891330642261
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.1529894,  1.       ], dtype=float32)}
episode index:297
target Thresh 30.850805848565013
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5.0000963, 26.       ], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: -0.02450755258112287
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2490634, 0.       ], dtype=float32)}
episode index:298
target Thresh 30.862240521426273
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 3.4317446, 22.       ], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: -0.02337605375613584
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.8301121,  0.       ], dtype=float32)}
episode index:299
target Thresh 30.873561417391542
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 10.], dtype=float32)}
done in step count: 199
reward sum = 0.0
running average episode reward sum: -0.02329813357694872
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-4.9698315 ,  0.60409224], dtype=float32)}
episode index:300
target Thresh 30.884769668559848
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: -0.02179060751855354
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.00193024,  1.        ], dtype=float32)}
episode index:301
target Thresh 30.895866395765648
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.02056388881782985
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.727428,  0.      ], dtype=float32)}
episode index:302
target Thresh 30.90685270869091
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 20.], dtype=float32)}
done in step count: 199
reward sum = 0.0
running average episode reward sum: -0.02049602119796903
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-4.001745  ,  0.17645693], dtype=float32)}
episode index:303
target Thresh 30.917729705976082
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000167, 4.       ], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: -0.017764126391396767
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9999995, 0.       ], dtype=float32)}
episode index:304
target Thresh 30.928498475329956
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  7.], dtype=float32)}
done in step count: 199
reward sum = 0.0
running average episode reward sum: -0.017705883354047925
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-4.8083997,  1.0760934], dtype=float32)}
episode index:305
target Thresh 30.939160093638442
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.016084959225439923
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0005069, 0.       ], dtype=float32)}
episode index:306
target Thresh 30.94971562707226
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.01511259930457204
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., -1.], dtype=float32)}
episode index:307
target Thresh 30.96016613119354
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  1.], dtype=float32)}
done in step count: 16
reward sum = 0.18530201888518416
running average episode reward sum: -0.014461902492267637
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.09727812,  0.31958818], dtype=float32)}
episode index:308
target Thresh 30.97051265106141
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: -0.011502478859606577
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:309
target Thresh 30.980756221336478
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 14.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: -0.01064541737027591
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -0.4880954], dtype=float32)}
episode index:310
target Thresh 30.990897866384305
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.009490035191914895
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:311
target Thresh 31.00093860037785
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.988998, 27.      ], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: -0.011850046031578949
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9871593, 1.       ], dtype=float32)}
episode index:312
target Thresh 31.01087942739888
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: -0.010574421319017993
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.2397766e-05,  1.0000000e+00], dtype=float32)}
episode index:313
target Thresh 31.02072134153838
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 8.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.008660203416728128
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.5299530e-05, -1.9999949e+00], dtype=float32)}
episode index:314
target Thresh 31.030465326995966
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  6.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.007736109004354387
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       , -1.9646425], dtype=float32)}
episode index:315
target Thresh 31.0401123581783
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 6.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: -0.005635361823960861
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.9999992], dtype=float32)}
episode index:316
target Thresh 31.049663399796543
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: -0.004726639747289059
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:317
target Thresh 31.059119406962818
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: -0.003615303018209534
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.06794584], dtype=float32)}
episode index:318
target Thresh 31.06848132528572
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  3.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: -0.0021046064570239237
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.7410222], dtype=float32)}
episode index:319
target Thresh 31.077750090964884
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.9151433, 11.       ], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: -0.00025274831184572374
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.08485818,  1.0000001 ], dtype=float32)}
episode index:320
target Thresh 31.086926630884598
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 13.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.0009549564772877523
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.88046503], dtype=float32)}
episode index:321
target Thresh 31.0960118627065
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.   , 15.889], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.001926557842544623
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.5351776], dtype=float32)}
episode index:322
target Thresh 31.105006694961354
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 15.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.003253309087614145
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.86485994], dtype=float32)}
episode index:323
target Thresh 31.113912027139868
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.      , 13.495415], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.004439010260183237
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.33617425], dtype=float32)}
episode index:324
target Thresh 31.12272874978269
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 15.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.005294365725478058
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.8061868], dtype=float32)}
episode index:325
target Thresh 31.131457744569428
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.994277, 21.      ], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.006347691106994997
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0210562, 1.0000006], dtype=float32)}
episode index:326
target Thresh 31.140099884406833
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  5.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.007513051345199906
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.6111702], dtype=float32)}
episode index:327
target Thresh 31.148656033516094
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  4.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.00867130572829381
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.4217242], dtype=float32)}
episode index:328
target Thresh 31.157127047519253
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 10.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.00970476206377012
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.20848072], dtype=float32)}
episode index:329
target Thresh 31.165513773524765
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 14.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.010731955027516272
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.05968869], dtype=float32)}
episode index:330
target Thresh 31.173817050212225
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.011752941387251872
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.42319846, 1.0000001 ], dtype=float32)}
episode index:331
target Thresh 31.182037707916216
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 11.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.013014128943314367
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.7804734], dtype=float32)}
episode index:332
target Thresh 31.19017656870936
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.       ,  7.9967985], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.014570966393935044
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.47883213], dtype=float32)}
episode index:333
target Thresh 31.19823444648452
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 16.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.015372938160662783
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.7052021], dtype=float32)}
episode index:334
target Thresh 31.20621214703619
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.017285556255705582
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3.259182e-02, 7.021427e-05], dtype=float32)}
episode index:335
target Thresh 31.214110468141072
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.      , 12.000002], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.018168071255212408
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.28282917], dtype=float32)}
episode index:336
target Thresh 31.221930199637857
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.020061044337541155
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.4459126], dtype=float32)}
episode index:337
target Thresh 31.229672123506212
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.020930125851601682
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:338
target Thresh 31.237337013944973
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 14.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.0217015105437238
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.85372794], dtype=float32)}
episode index:339
target Thresh 31.24492563744958
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.02320074433624226
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:340
target Thresh 31.252438752888697
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.024395074147572925
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:341
target Thresh 31.25987711158013
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  4.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.02558241957404201
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0906985], dtype=float32)}
episode index:342
target Thresh 31.267241457365955
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  7.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.02690228686391361
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0723407], dtype=float32)}
episode index:343
target Thresh 31.274532526686883
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 11.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.027837682658204556
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.3555117], dtype=float32)}
episode index:344
target Thresh 31.28175104865592
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.028879951662093818
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.5665122, 1.       ], dtype=float32)}
episode index:345
target Thresh 31.28889774513128
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 14.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.030040608478099327
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.33811024], dtype=float32)}
episode index:346
target Thresh 31.295973330788563
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  7.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.03119457562945927
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.1722096], dtype=float32)}
episode index:347
target Thresh 31.302978513192237
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 2.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.0334325222512137
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.2474607], dtype=float32)}
episode index:348
target Thresh 31.309913992866377
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.       ,  6.9999943], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.034145980744708794
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.5428703], dtype=float32)}
episode index:349
target Thresh 31.31678046336473
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5.9999986, 26.       ], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.031917525322103624
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-2.7507687e-01,  9.4532967e-05], dtype=float32)}
episode index:350
target Thresh 31.323578611340064
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.033340669124604747
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.000001], dtype=float32)}
episode index:351
target Thresh 31.33030911661285
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 17.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.03423651506487576
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.6289562], dtype=float32)}
episode index:352
target Thresh 31.33697265223922
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.03599816799670331
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.00112581], dtype=float32)}
episode index:353
target Thresh 31.343569884578287
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 19.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.03678294886702336
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.45153785], dtype=float32)}
episode index:354
target Thresh 31.350101473358787
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 13.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.03802665013782047
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.8801949], dtype=float32)}
episode index:355
target Thresh 31.356568071745038
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 11.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.039263364322826594
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.66633236], dtype=float32)}
episode index:356
target Thresh 31.362970326402266
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  6.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.04003240418772064
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.2296536], dtype=float32)}
episode index:357
target Thresh 31.369308877561277
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.04175326339390019
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0152843], dtype=float32)}
episode index:358
target Thresh 31.375584359082467
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  5.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.04328177798054671
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9951341], dtype=float32)}
episode index:359
target Thresh 31.381797398519215
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 4.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.045186550819489635
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.5573223], dtype=float32)}
episode index:360
target Thresh 31.387948617180648
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.046878831842150324
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:361
target Thresh 31.39403863019375
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.999995, 11.      ], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.04838052015197864
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000001,  1.       ], dtype=float32)}
episode index:362
target Thresh 31.400068046564904
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.049111732482386414
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:363
target Thresh 31.406037469240772
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.05059903541512711
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.963145,  1.      ], dtype=float32)}
episode index:364
target Thresh 31.41194749516859
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.05292616134549662
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:365
target Thresh 31.41779871535588
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.05373422768089143
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9999995, 1.       ], dtype=float32)}
episode index:366
target Thresh 31.423591714929536
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.05537555131118873
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999344e+00, 1.4305115e-06], dtype=float32)}
episode index:367
target Thresh 31.429327073194344
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.05627784733751702
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.000000e+00, 2.861023e-06], dtype=float32)}
episode index:368
target Thresh 31.43500536369091
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.       ,  2.2631197], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.05742153040706304
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.3941809], dtype=float32)}
episode index:369
target Thresh 31.440627154253015
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  7.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.05855903140596287
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.68850225], dtype=float32)}
episode index:370
target Thresh 31.446193007064398
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.05999280760163413
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00517511, 1.        ], dtype=float32)}
episode index:371
target Thresh 31.45170347871498
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 15.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.06076884424813511
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0013951], dtype=float32)}
episode index:372
target Thresh 31.45715912025652
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.3000000e+01, 1.9311905e-05], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.062030699893582474
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -1.054225], dtype=float32)}
episode index:373
target Thresh 31.462560477257714
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  2.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.06314371112381353
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.90699625], dtype=float32)}
episode index:374
target Thresh 31.467908089858767
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.       ,  1.0000012], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.06425078629415003
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0454872], dtype=float32)}
episode index:375
target Thresh 31.473202492825397
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  5.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.0656503586710273
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -0.903671], dtype=float32)}
episode index:376
target Thresh 31.478444215602305
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 17.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.06650386034298744
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.6300888e-04, -9.9963725e-01], dtype=float32)}
episode index:377
target Thresh 31.483633782366148
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8.000009, 21.      ], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.06725035394022821
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.6863213, 1.       ], dtype=float32)}
episode index:378
target Thresh 31.488771712077916
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 10.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.06833490947072893
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.57558876], dtype=float32)}
episode index:379
target Thresh 31.49385851853487
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.06955360970896385
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99957895, 1.        ], dtype=float32)}
episode index:380
target Thresh 31.49889471042189
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  7.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.07011233917555712
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.2286391], dtype=float32)}
episode index:381
target Thresh 31.503880791362363
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  5.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.07105567653373629
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.22511202], dtype=float32)}
episode index:382
target Thresh 31.50881725996854
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.07160756650748894
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3.4120083e-02, 1.1920929e-07], dtype=float32)}
episode index:383
target Thresh 31.51370460989139
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.07232910524080276
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.9866166, -0.9993106], dtype=float32)}
episode index:384
target Thresh 31.518543329869985
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.07367497769472274
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0092590e+00, 1.1920929e-07], dtype=float32)}
episode index:385
target Thresh 31.52333390378035
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.07448778990017683
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9948044, 1.       ], dtype=float32)}
episode index:386
target Thresh 31.52807681068387
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.07519629287226941
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7.6293945e-06, 1.0000000e+00], dtype=float32)}
episode index:387
target Thresh 31.532772524875192
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.07590114376718624
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2351685e+00, 1.1920929e-07], dtype=float32)}
episode index:388
target Thresh 31.537421515929637
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 18.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.07651273618960992
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.07683206], dtype=float32)}
episode index:389
target Thresh 31.542024248750195
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 15.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.07712119224063657
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.52021503], dtype=float32)}
episode index:390
target Thresh 31.54658118361398
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 10.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.07828313548298789
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00122237, 0.25605467], dtype=float32)}
episode index:391
target Thresh 31.55109277621828
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.07918156424451088
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9616051e-01,  2.3841858e-07], dtype=float32)}
episode index:392
target Thresh 31.555559477726106
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 3.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.08104115313956302
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9974661], dtype=float32)}
episode index:393
target Thresh 31.559981734811338
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.08172043559377733
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99977195], dtype=float32)}
episode index:394
target Thresh 31.564359989703366
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.07962541318172447
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.5067921,  1.       ], dtype=float32)}
episode index:395
target Thresh 31.56869468023133
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 14.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.08051137731510397
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -1.197655], dtype=float32)}
episode index:396
target Thresh 31.572986239867898
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  2.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.08101998728781402
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.2092471], dtype=float32)}
episode index:397
target Thresh 31.577235097772608
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.08189799538508083
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.8068347,  1.       ], dtype=float32)}
episode index:398
target Thresh 31.581441678834786
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 11.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.08247922997331371
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.8141929], dtype=float32)}
episode index:399
target Thresh 31.58560640371605
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.08297910573958292
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99471176, 1.        ], dtype=float32)}
episode index:400
target Thresh 31.589729688892355
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.08373831118412262
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.06660366, 1.        ], dtype=float32)}
episode index:401
target Thresh 31.593811946695656
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.08499888752446062
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:402
target Thresh 31.597853585355136
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.0865969051732833
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:403
target Thresh 31.60185500903803
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 1.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.08818701184364647
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0956532], dtype=float32)}
episode index:404
target Thresh 31.605816617890035
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.08915024613539053
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:405
target Thresh 31.609738808075345
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.09038507311535264
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5.527906e-01, 9.536743e-07], dtype=float32)}
episode index:406
target Thresh 31.613621971816244
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.09146874861138371
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:407
target Thresh 31.61746649743234
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 16.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.09193678975812296
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.27454495], dtype=float32)}
episode index:408
target Thresh 31.621272769379402
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.09265924379049918
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:409
target Thresh 31.625041168287794
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  3.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.0932836808546687
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.      , -0.980863], dtype=float32)}
episode index:410
target Thresh 31.628772071000547
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.09434975705696878
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:411
target Thresh 31.632465850611045
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  9.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.09488242899636935
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0961576], dtype=float32)}
episode index:412
target Thresh 31.636122876500323
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.0956949829455307
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.8782213,  1.       ], dtype=float32)}
episode index:413
target Thresh 31.639743514374018
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 18.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.09614603259175163
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.4658674], dtype=float32)}
episode index:414
target Thresh 31.64332812629894
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.09786616263369921
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:415
target Thresh 31.646877070739258
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.0986656843821759
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 3.5762787e-07], dtype=float32)}
episode index:416
target Thresh 31.650390702592386
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.09664055464224959
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:417
target Thresh 31.653869373224428
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.0972435160907131
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:418
target Thresh 31.657313430505347
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 12.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.09768548749975914
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.4607489], dtype=float32)}
episode index:419
target Thresh 31.66072321884375
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.09871823871999781
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000006e+00, 4.6849251e-05], dtype=float32)}
episode index:420
target Thresh 31.664099079221298
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.09931196841448713
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:421
target Thresh 31.667441349226856
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 1.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.10063137133293622
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.99478495], dtype=float32)}
episode index:422
target Thresh 31.6707503630902
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.10211687636524605
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:423
target Thresh 31.67402645171548
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.10342344033608275
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9998306, 1.       ], dtype=float32)}
episode index:424
target Thresh 31.677269942714283
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.10400051092376256
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99763656,  0.        ], dtype=float32)}
episode index:425
target Thresh 31.68048116043842
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1044930228607725
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.00851011,  0.        ], dtype=float32)}
episode index:426
target Thresh 31.683660426012327
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.10250167288412644
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000005,  0.       ], dtype=float32)}
episode index:427
target Thresh 31.686808057365223
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.10292206508879202
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99999905, 1.        ], dtype=float32)}
episode index:428
target Thresh 31.689924369262858
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.10349492377180183
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.7225766,  0.       ], dtype=float32)}
episode index:429
target Thresh 31.693009673339024
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.1043665562746581
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.00274086,  0.        ], dtype=float32)}
episode index:430
target Thresh 31.6960642781267
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.10239398093024567
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0621973e+00,  1.1920929e-07], dtype=float32)}
episode index:431
target Thresh 31.699088489088904
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.10296408384499048
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.02878809, 1.        ], dtype=float32)}
episode index:432
target Thresh 31.70208260864926
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 13.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.10362102704396278
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0027809], dtype=float32)}
episode index:433
target Thresh 31.705046936222214
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.10403302821778083
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9695491e+00, 1.4305115e-06], dtype=float32)}
episode index:434
target Thresh 31.707981768242995
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.10478345162417675
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8.5353851e-05, 2.3841858e-07], dtype=float32)}
episode index:435
target Thresh 31.71088739819725
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.10543170170990111
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0687822e+00, 6.3180923e-06], dtype=float32)}
episode index:436
target Thresh 31.7137641166504
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  9.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.10583673108008669
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.7183918], dtype=float32)}
episode index:437
target Thresh 31.716612211276683
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.10647961637214129
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999987, 1.       ], dtype=float32)}
episode index:438
target Thresh 31.719431966887935
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.10773159902277422
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0037775], dtype=float32)}
episode index:439
target Thresh 31.722223665462067
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.10579172398597907
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.8500047, 1.       ], dtype=float32)}
episode index:440
target Thresh 31.724987586171267
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.10703958855743943
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:441
target Thresh 31.727724005409904
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  3.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.10799977274622351
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.7224903], dtype=float32)}
episode index:442
target Thresh 31.730433196822187
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 4.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.10958442337207853
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000144e+00, 7.3909760e-06], dtype=float32)}
episode index:443
target Thresh 31.733115431329512
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 12.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.11030713235097027
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.02820635], dtype=float32)}
episode index:444
target Thresh 31.735770977157564
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.11069392427036358
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9253805e+00, 2.0265579e-06], dtype=float32)}
episode index:445
target Thresh 31.738400099863142
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1113143874199816
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.1495087e+00, 3.5762787e-06], dtype=float32)}
episode index:446
target Thresh 31.741003062360704
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 6.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.11253314717966845
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.8805261], dtype=float32)}
episode index:447
target Thresh 31.74358012494867
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 14.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.11298242719955758
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.00608861], dtype=float32)}
episode index:448
target Thresh 31.74613154533545
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.11359364782717549
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0976354, 1.       ], dtype=float32)}
episode index:449
target Thresh 31.748657578665206
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.11396883869085066
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:450
target Thresh 31.751158477543374
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.11206244787963568
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.1232035, 1.       ], dtype=float32)}
episode index:451
target Thresh 31.753634492061927
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.      ,  5.999528], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.11267164708565419
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.09811604], dtype=float32)}
episode index:452
target Thresh 31.756085869824382
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 1.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.11421100327310309
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0835757], dtype=float32)}
episode index:453
target Thresh 31.758512855970555
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  5.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.11472745137184075
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.8285149], dtype=float32)}
episode index:454
target Thresh 31.760915693201085
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 6.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.1159172811490455
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.8787084], dtype=float32)}
episode index:455
target Thresh 31.763294621801702
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.11710189237459584
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.81484425], dtype=float32)}
episode index:456
target Thresh 31.76564987966724
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.       ,  3.9999995], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.11778759328843699
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.       ,  0.0219481], dtype=float32)}
episode index:457
target Thresh 31.767981702325454
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.11912211819392075
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:458
target Thresh 31.77029032296055
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.11947790777624553
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9974905], dtype=float32)}
episode index:459
target Thresh 31.772575972436517
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 12.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1200603916484711
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.5999465], dtype=float32)}
episode index:460
target Thresh 31.774838879320207
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.12073372531083884
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9999949,  1.       ], dtype=float32)}
episode index:461
target Thresh 31.777079269904196
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.12140414410886734
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9999809, 1.       ], dtype=float32)}
episode index:462
target Thresh 31.779297368229404
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.11953110401971838
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9999852,  1.       ], dtype=float32)}
episode index:463
target Thresh 31.781493396107518
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.12010845183217589
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.5100703], dtype=float32)}
episode index:464
target Thresh 31.783667573143155
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  4.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1204575294335712
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.4770468], dtype=float32)}
episode index:465
target Thresh 31.785820116755826
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2.0005522, 21.       ], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.12094727387706139
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9987627, 1.       ], dtype=float32)}
episode index:466
target Thresh 31.78795124220169
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.12143492091394135
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9640362, 1.       ], dtype=float32)}
episode index:467
target Thresh 31.790061162595066
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 3.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.12309852151027909
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:468
target Thresh 31.79215008892975
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.12350515706375396
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9940335, 1.       ], dtype=float32)}
episode index:469
target Thresh 31.79421823010012
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.8000000e+01, 2.3841858e-07], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.12406667904659704
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.8938141], dtype=float32)}
episode index:470
target Thresh 31.796265792922014
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 12.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.12462581664734737
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.5763766], dtype=float32)}
episode index:471
target Thresh 31.79829298215342
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 2.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.12590627042563687
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.56360257], dtype=float32)}
episode index:472
target Thresh 31.800300000514955
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  2.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.12688847704207315
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.21491921], dtype=float32)}
episode index:473
target Thresh 31.80228704871012
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.12504733380534494
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9881576e+00, 5.9604645e-07], dtype=float32)}
episode index:474
target Thresh 31.8042543254454
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1253786647583463
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:475
target Thresh 31.806202027450098
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.12592917279246743
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.000047,  1.      ], dtype=float32)}
episode index:476
target Thresh 31.808130349496043
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.12625726579810376
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 2.1457672e-06], dtype=float32)}
episode index:477
target Thresh 31.810039484417047
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.1273657234010366
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.133522], dtype=float32)}
episode index:478
target Thresh 31.81192962312819
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.12846955278850836
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0018682e+00,  3.5762787e-07], dtype=float32)}
episode index:479
target Thresh 31.813800954644922
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.12930907663686564
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0275865e+00, 2.3841858e-06], dtype=float32)}
episode index:480
target Thresh 31.81565366610195
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 20.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.12962741439121933
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.35694087], dtype=float32)}
episode index:481
target Thresh 31.81748794277197
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3.7183604, 8.       ], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.13071968116634128
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-2.8163958e-01,  1.1920929e-07], dtype=float32)}
episode index:482
target Thresh 31.819303968084167
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  2.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.13154933192997204
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.5738982], dtype=float32)}
episode index:483
target Thresh 31.821101923642598
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.9337835, 13.       ], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.13237555438466217
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0703418, 1.       ], dtype=float32)}
episode index:484
target Thresh 31.82288198924431
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1327496472541577
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7.200241e-05, 1.000000e+00], dtype=float32)}
episode index:485
target Thresh 31.824644342897344
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.13397649983182403
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.7348142e-01,  3.5762787e-07], dtype=float32)}
episode index:486
target Thresh 31.826389160838538
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.13216994969424925
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.8857176e-01,  1.1920929e-07], dtype=float32)}
episode index:487
target Thresh 31.828116617551142
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  9.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.13254216413358477
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.7379801], dtype=float32)}
episode index:488
target Thresh 31.829826885782264
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 10.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.13315141780611325
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4346113], dtype=float32)}
episode index:489
target Thresh 31.83152013656015
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  8.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.13359126887201914
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.4536593], dtype=float32)}
episode index:490
target Thresh 31.833196539211293
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  1.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.13429331700058939
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0041906], dtype=float32)}
episode index:491
target Thresh 31.834856261377357
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 12.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.13465818951906378
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5093093], dtype=float32)}
episode index:492
target Thresh 31.836499469031935
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.13509230767440036
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9768496, 1.       ], dtype=float32)}
episode index:493
target Thresh 31.838126326497168
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 17.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.13560309346655744
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99974716], dtype=float32)}
episode index:494
target Thresh 31.839736996460154
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.13596310862337246
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9785056, 1.       ], dtype=float32)}
episode index:495
target Thresh 31.84133163998923
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  9.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.13665329771888984
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9973172], dtype=float32)}
episode index:496
target Thresh 31.842910416550087
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  3.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1369466100705239
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.17178953], dtype=float32)}
episode index:497
target Thresh 31.844473484021687
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1374495696667678
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:498
target Thresh 31.846020998712085
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.13780299857743558
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99999964,  1.        ], dtype=float32)}
episode index:499
target Thresh 31.847553115374037
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 14.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1381550137724607
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5299062], dtype=float32)}
episode index:500
target Thresh 31.849069987220485
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.13894001574097875
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2.0980835e-05, 0.0000000e+00], dtype=float32)}
episode index:501
target Thresh 31.850571765939883
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  0.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.13943499676340707
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4264033], dtype=float32)}
episode index:502
target Thresh 31.85205860171135
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.13992800967043806
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:503
target Thresh 31.853530643219703
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 11.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.14027301480222287
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.75581944], dtype=float32)}
episode index:504
target Thresh 31.854988037670317
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  0.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.14084765677291156
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.4502016], dtype=float32)}
episode index:505
target Thresh 31.856430930803857
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  6.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.14173627800458566
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.30232513], dtype=float32)}
episode index:506
target Thresh 31.857859466910835
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.14275080211108548
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0228726, 1.       ], dtype=float32)}
episode index:507
target Thresh 31.859273788846053
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  6.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.14341132592582745
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.07541883], dtype=float32)}
episode index:508
target Thresh 31.860674038042887
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7.9999886, 23.       ], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.14374609855876294
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.7180896,  1.       ], dtype=float32)}
episode index:509
target Thresh 31.862060354527415
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  0.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.14414792667943202
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.2260466], dtype=float32)}
episode index:510
target Thresh 31.86343287693245
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.14441853648334899
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:511
target Thresh 31.86479174251137
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  1.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.14528976981052996
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.3240086], dtype=float32)}
episode index:512
target Thresh 31.866137087151866
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 16.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.14576175951655232
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.20900476], dtype=float32)}
episode index:513
target Thresh 31.867469045389527
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.14602765013321467
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9988153e+00, 1.9073486e-06], dtype=float32)}
episode index:514
target Thresh 31.868787750421284
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  8.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.14649637409217928
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.5507697], dtype=float32)}
episode index:515
target Thresh 31.870093334118735
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  8.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1468206264603921
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.71642447], dtype=float32)}
episode index:516
target Thresh 31.871385927041345
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.145094061579101
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99986494,  1.        ], dtype=float32)}
episode index:517
target Thresh 31.87266565844948
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 15.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.145644974993041
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9996569], dtype=float32)}
episode index:518
target Thresh 31.87393265631735
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.14590852906141855
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.39959884, 0.        ], dtype=float32)}
episode index:519
target Thresh 31.875187047345793
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.14617106946030237
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999914e+00, 1.4305115e-06], dtype=float32)}
episode index:520
target Thresh 31.87642895697496
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  7.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.14680854706210603
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.99583375], dtype=float32)}
episode index:521
target Thresh 31.877658509396845
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  7.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.14754539084168053
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9984468], dtype=float32)}
episode index:522
target Thresh 31.87887582756772
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.14780329551785515
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.9114227e-05, 1.1920929e-07], dtype=float32)}
episode index:523
target Thresh 31.880081033220417
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 3.0000005, 13.       ], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.14853542854167603
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99997985,  1.        ], dtype=float32)}
episode index:524
target Thresh 31.881274246876504
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.1468319069308022
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.09286761, 1.        ], dtype=float32)}
episode index:525
target Thresh 31.882455587858338
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  6.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.14767536338150408
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.01922476], dtype=float32)}
episode index:526
target Thresh 31.883625174301002
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.14799061050239307
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.85496974, 1.        ], dtype=float32)}
episode index:527
target Thresh 31.88478312316412
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  2.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.148716842300684
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.9845936], dtype=float32)}
episode index:528
target Thresh 31.88592955024354
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.14909484154038025
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.26915646], dtype=float32)}
episode index:529
target Thresh 31.887064570182922
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.14934641643649463
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  0.], dtype=float32)}
episode index:530
target Thresh 31.88818829648521
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3.8925786, 5.       ], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.15059058514377052
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.1074214,  1.       ], dtype=float32)}
episode index:531
target Thresh 31.889300841523973
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 21.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1508384027214721
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.9967662], dtype=float32)}
episode index:532
target Thresh 31.890402316554635
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.1517863606900997
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:533
target Thresh 31.891492831725625
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.15010546222969295
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.74656e+00, 3.33786e-06], dtype=float32)}
episode index:534
target Thresh 31.89257249608936
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1503527969479197
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:535
target Thresh 31.893641417613182
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.15096463296107657
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9985846e+00, 3.2186508e-06], dtype=float32)}
episode index:536
target Thresh 31.894699703190135
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.15190529472464998
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9999952e-01,  2.3841858e-07], dtype=float32)}
episode index:537
target Thresh 31.895747458649655
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.15272050793148148
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99477136,  1.        ], dtype=float32)}
episode index:538
target Thresh 31.896784788768162
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.153084066247193
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.0386677e-02, 2.3841858e-07], dtype=float32)}
episode index:539
target Thresh 31.897811797279534
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 18.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.15338170796912412
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.5690901], dtype=float32)}
episode index:540
target Thresh 31.898828586885475
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.15476177874921818
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:541
target Thresh 31.899835259265796
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  0.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.15535870701720855
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.3103207], dtype=float32)}
episode index:542
target Thresh 31.900831915088574
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1555927232777312
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9992285], dtype=float32)}
episode index:543
target Thresh 31.901818654020218
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.15588356495569491
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0324907e-01,  5.9604645e-07], dtype=float32)}
episode index:544
target Thresh 31.90279557473545
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  1.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.1565726611667854
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0255562], dtype=float32)}
episode index:545
target Thresh 31.90376277492715
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  4.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.15716189969944697
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.9605093], dtype=float32)}
episode index:546
target Thresh 31.90472035131614
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 10.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1573909081761957
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.9967471], dtype=float32)}
episode index:547
target Thresh 31.905668399660865
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  4.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.1580734813364581
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.0010922], dtype=float32)}
episode index:548
target Thresh 31.906607014766948
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1583571554981221
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0095820e+00,  2.0861626e-05], dtype=float32)}
episode index:549
target Thresh 31.90753629049668
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  6.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1585827416453637
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.48892248], dtype=float32)}
episode index:550
target Thresh 31.908456319778406
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.15886446188936484
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00915146, 1.        ], dtype=float32)}
episode index:551
target Thresh 31.90936719461582
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.1593564958533334
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.00010765], dtype=float32)}
episode index:552
target Thresh 31.910269006097174
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  7.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.16013612244311037
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.17208803], dtype=float32)}
episode index:553
target Thresh 31.91116184440436
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1604135131897654
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.950638e-01,  9.179115e-06], dtype=float32)}
episode index:554
target Thresh 31.912045798821953
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.       ,  3.1525126], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.16082253476780184
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.22150338], dtype=float32)}
episode index:555
target Thresh 31.912920957746135
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.16116040510113314
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.03079128, 1.        ], dtype=float32)}
episode index:556
target Thresh 31.913787408693523
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.16156661710095158
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999523, 1.       ], dtype=float32)}
episode index:557
target Thresh 31.914645238309937
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.16222947441797494
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000000e+00,  5.9604645e-07], dtype=float32)}
episode index:558
target Thresh 31.915494532379054
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  5.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.162632320597907
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.5322022], dtype=float32)}
episode index:559
target Thresh 31.916335375830986
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 11.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.1629645458113036
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.51517904], dtype=float32)}
episode index:560
target Thresh 31.917167852750783
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 18.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1632334336014617
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9890131 , 0.00821149], dtype=float32)}
episode index:561
target Thresh 31.917992046386825
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 10.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.1635013644955694
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.        ,  0.05883992], dtype=float32)}
episode index:562
target Thresh 31.918808039159167
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  5.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.16376834359253997
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.9369953], dtype=float32)}
episode index:563
target Thresh 31.919615912667766
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.16477052738049644
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99380875], dtype=float32)}
episode index:564
target Thresh 31.92041574770064
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  3.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.16552401317274337
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9402864], dtype=float32)}
episode index:565
target Thresh 31.92120762424197
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 15.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.16573056003371203
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.6954228], dtype=float32)}
episode index:566
target Thresh 31.92199162148006
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.16702556786434042
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9998181e+00, 1.7881393e-06], dtype=float32)}
episode index:567
target Thresh 31.92276781781529
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.167667144329368
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9999999,  1.       ], dtype=float32)}
episode index:568
target Thresh 31.923536290867943
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.16792398695109143
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9528165, 1.       ], dtype=float32)}
episode index:569
target Thresh 31.924297117485963
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.16812487388009126
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99644697], dtype=float32)}
episode index:570
target Thresh 31.925050373752644
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.1684410797753976
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.055296,  1.      ], dtype=float32)}
episode index:571
target Thresh 31.925796134994243
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.16898278575481124
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0076599,  1.       ], dtype=float32)}
episode index:572
target Thresh 31.926534475787506
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.16918077310337354
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.92453384, 1.        ], dtype=float32)}
episode index:573
target Thresh 31.92726546996712
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.16758670656980126
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.7676229e-01, 7.6293945e-06], dtype=float32)}
episode index:574
target Thresh 31.927989190633127
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.1680438900540277
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000421e+00, 7.6293945e-06], dtype=float32)}
episode index:575
target Thresh 31.928705710158184
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2.0000000e+01, 1.1920929e-07], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.16835749170341308
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.20200658], dtype=float32)}
episode index:576
target Thresh 31.929415100194845
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.16855519022122517
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00674152, 1.        ], dtype=float32)}
episode index:577
target Thresh 31.930117431682703
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.16893384990769364
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.1920929e-07,  2.3841858e-07], dtype=float32)}
episode index:578
target Thresh 31.930812774855497
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.16946815569369073
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9945474, 1.       ], dtype=float32)}
episode index:579
target Thresh 31.931501199248117
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.1697771389426671
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.7683716e-07, 1.0728836e-06], dtype=float32)}
episode index:580
target Thresh 31.93218277370358
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.17073965677581227
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000001e+00, 2.6226044e-05], dtype=float32)}
episode index:581
target Thresh 31.9328575663799
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 11.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.171111960611249
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.15974927], dtype=float32)}
episode index:582
target Thresh 31.933525644756905
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.16953918980888477
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.5991606e+00,  2.5033951e-06], dtype=float32)}
episode index:583
target Thresh 31.934187075642992
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 14.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.16978622988813324
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.      , -0.223086], dtype=float32)}
episode index:584
target Thresh 31.934841925181797
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 11.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.17040444317037576
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.98360825], dtype=float32)}
episode index:585
target Thresh 31.935490258858824
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.17077477771957306
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 1.3113022e-06], dtype=float32)}
episode index:586
target Thresh 31.936132141507976
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 4.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.17186374743384977
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 1.4305115e-06], dtype=float32)}
episode index:587
target Thresh 31.936767637318056
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  4.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.17230354924093505
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.02838695], dtype=float32)}
episode index:588
target Thresh 31.937396809839175
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.17074477680221173
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-6.8422389e-01,  5.9604645e-07], dtype=float32)}
episode index:589
target Thresh 31.938019721989107
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.17126605158729274
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000465, 1.0000001], dtype=float32)}
episode index:590
target Thresh 31.93863643605959
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  3.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.17170463222758497
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.9951627], dtype=float32)}
episode index:591
target Thresh 31.93924701372254
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.      ,  1.000006], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.17231229501098433
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.03056359], dtype=float32)}
episode index:592
target Thresh 31.939851516036235
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.       ,  1.0007026], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.17260970840911083
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.10191798], dtype=float32)}
episode index:593
target Thresh 31.94045000345141
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  4.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17284742034123354
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.7452815], dtype=float32)}
episode index:594
target Thresh 31.941042535817303
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17308433324165162
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9997449e-01,  7.1525574e-07], dtype=float32)}
episode index:595
target Thresh 31.94162917238765
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17332045113233677
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.8795756e+00, 4.5299530e-06], dtype=float32)}
episode index:596
target Thresh 31.942209971826593
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17355577800831276
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.36938143, 1.        ], dtype=float32)}
episode index:597
target Thresh 31.942784992214555
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 16.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.17384862526933564
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.44804752], dtype=float32)}
episode index:598
target Thresh 31.943354291054064
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.1744456075309895
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 5.9604645e-06], dtype=float32)}
episode index:599
target Thresh 31.94391792527547
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17467788251192118
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.7918510e-04, 3.5762787e-07], dtype=float32)}
episode index:600
target Thresh 31.944475951242673
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17490938453118587
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:601
target Thresh 31.94502842475873
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 2.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.17596435233096794
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.9792724], dtype=float32)}
episode index:602
target Thresh 31.945575401071448
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.       ,  2.3296485], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.1765538658428569
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.9946624], dtype=float32)}
episode index:603
target Thresh 31.946116934878923
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 21.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17678111208498792
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.89250946], dtype=float32)}
episode index:604
target Thresh 31.946653080334983
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 12.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.17712927634435155
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.9846804], dtype=float32)}
episode index:605
target Thresh 31.947183891054618
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 7.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.17791965707645657
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99908006], dtype=float32)}
episode index:606
target Thresh 31.94770942011935
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.1784145125013718
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9983466e-01,  1.1920929e-07], dtype=float32)}
episode index:607
target Thresh 31.948229720082512
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 13.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17863720342832676
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.6900034], dtype=float32)}
episode index:608
target Thresh 31.948744842974545
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 22.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.17880763418867598
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.02458763, 1.8303795 ], dtype=float32)}
episode index:609
target Thresh 31.94925484030816
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.17902895051966175
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-8.9527762e-01,  1.1920929e-07], dtype=float32)}
episode index:610
target Thresh 31.949759763083517
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 14.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.17915195810118914
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9952382 ,  0.00716984], dtype=float32)}
episode index:611
target Thresh 31.950259661793318
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  6.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.1796407570258604
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.01096427], dtype=float32)}
episode index:612
target Thresh 31.95075458642785
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.17991651181064694
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.07919884], dtype=float32)}
episode index:613
target Thresh 31.95124458647998
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1800834711342143
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.999598, 0.      ], dtype=float32)}
episode index:614
target Thresh 31.951729710950133
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 14.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1804206044965977
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.5846262], dtype=float32)}
episode index:615
target Thresh 31.952210008351155
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1805862034121568
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.7348099, 1.       ], dtype=float32)}
episode index:616
target Thresh 31.952685526713186
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1807512655403073
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2290769, 0.       ], dtype=float32)}
episode index:617
target Thresh 31.95315631358846
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.18096657190042004
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9516940e-01,  1.1920929e-07], dtype=float32)}
episode index:618
target Thresh 31.953622416056056
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.18113048622122874
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:619
target Thresh 31.954083880726614
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.18160978688861387
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.3259959, 0.       ], dtype=float32)}
episode index:620
target Thresh 31.954540753746976
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.18011635177741303
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.7665547e+00, 1.5497208e-06], dtype=float32)}
episode index:621
target Thresh 31.95499308080483
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 11.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.1805188451186069
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0001708], dtype=float32)}
episode index:622
target Thresh 31.95544090713326
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 4.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.1813992322050939
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.7052525], dtype=float32)}
episode index:623
target Thresh 31.95588427751527
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 11.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1815611397439976
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0057727], dtype=float32)}
episode index:624
target Thresh 31.95632323628827
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.1818285274245672
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:625
target Thresh 31.9567578273485
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.18248134127852159
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0712624, 0.       ], dtype=float32)}
episode index:626
target Thresh 31.95718809415543
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 12.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.18269079782527034
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.2461696], dtype=float32)}
episode index:627
target Thresh 31.957614079736096
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 16.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.18295510935755493
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.4228272], dtype=float32)}
episode index:628
target Thresh 31.958035826689418
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 14.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1832801735541248
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.26950014], dtype=float32)}
episode index:629
target Thresh 31.958453377190438
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 3.496105, 14.      ], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.18374845407229287
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.4961052e+00, 6.1988831e-06], dtype=float32)}
episode index:630
target Thresh 31.958866772994554
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 15.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.18407123067281222
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0993279], dtype=float32)}
episode index:631
target Thresh 31.95927605544169
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1843929858283932
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:632
target Thresh 31.959681265460436
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  4.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.1847137243800071
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.6029621], dtype=float32)}
episode index:633
target Thresh 31.960082443572126
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.18497234380543295
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.58333397, 1.        ], dtype=float32)}
episode index:634
target Thresh 31.960479629894913
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.18609837161046378
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 2.3841858e-07], dtype=float32)}
episode index:635
target Thresh 31.960872864147753
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 15.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.18629917699486556
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.2477584], dtype=float32)}
episode index:636
target Thresh 31.961262185654398
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.       ,  1.0000033], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.18684100089283281
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.19384027], dtype=float32)}
episode index:637
target Thresh 31.961647633347333
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.18729782832090047
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-2.3841858e-07,  1.0000000e+00], dtype=float32)}
episode index:638
target Thresh 31.96202924577164
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.18783639353479578
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:639
target Thresh 31.962407061088882
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 15.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.18821550418552266
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.00817966, -0.9994004 ], dtype=float32)}
episode index:640
target Thresh 31.962781117080905
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.188465836378837
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9987061e+00, 1.1920929e-06], dtype=float32)}
episode index:641
target Thresh 31.963151451153617
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 1.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.18957414504491357
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99958587], dtype=float32)}
episode index:642
target Thresh 31.963518100340742
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.18971855467389662
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.69031715, 0.        ], dtype=float32)}
episode index:643
target Thresh 31.9638811013075
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.1900923879896204
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:644
target Thresh 31.964240490354285
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.19033825783785355
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.035357, 0.      ], dtype=float32)}
episode index:645
target Thresh 31.964596303420308
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 11.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.1907099744820674
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0000465], dtype=float32)}
episode index:646
target Thresh 31.96494857608717
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  6.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.19095412976122958
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.7585257], dtype=float32)}
episode index:647
target Thresh 31.96529734358243
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2.0255103, 6.       ], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.19178444746221535
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.02551031, 0.        ], dtype=float32)}
episode index:648
target Thresh 31.96564264078313
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 18.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.19192411632048775
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.088596], dtype=float32)}
episode index:649
target Thresh 31.96598450221928
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  7.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.19216527681861006
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9999893], dtype=float32)}
episode index:650
target Thresh 31.966322962077303
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.19268643768371205
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:651
target Thresh 31.966658054203467
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  6.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.19287221093280144
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.32485878], dtype=float32)}
episode index:652
target Thresh 31.966989812107272
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1930093584451264
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.5311718, 0.       ], dtype=float32)}
episode index:653
target Thresh 31.967318268964775
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  7.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.1934455779276262
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.99995697], dtype=float32)}
episode index:654
target Thresh 31.96764345762194
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  5.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.19362934131413365
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99993885], dtype=float32)}
episode index:655
target Thresh 31.967965410597902
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.19433432707432552
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:656
target Thresh 31.96828416008823
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 13.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.19476653799202062
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.7483225, -0.9999871], dtype=float32)}
episode index:657
target Thresh 31.968599737968137
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.19527820130814216
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:658
target Thresh 31.968912175795676
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  3.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.19563508902998109
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0003432], dtype=float32)}
episode index:659
target Thresh 31.969221504814886
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.19606336450114778
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0021763, 1.       ], dtype=float32)}
episode index:660
target Thresh 31.96952775595893
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 3.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.1969921642522807
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -0.999998], dtype=float32)}
episode index:661
target Thresh 31.969830959853173
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 17.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.19727982033196
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.      , -0.999992], dtype=float32)}
episode index:662
target Thresh 31.97013114681826
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 11.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.19745558319132359
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.99856496], dtype=float32)}
episode index:663
target Thresh 31.970428346873142
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  9.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.19774167491693906
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0003436], dtype=float32)}
episode index:664
target Thresh 31.970722589738067
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  8.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.19786902508470455
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.37995696], dtype=float32)}
episode index:665
target Thresh 31.971013904837566
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 26.], dtype=float32)}
done in step count: 14
reward sum = -0.7712320754503899
running average episode reward sum: 0.19641391832714436
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.8265805, 0.5909867], dtype=float32)}
episode index:666
target Thresh 31.971302321303394
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 15.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.19664220096848298
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9997699], dtype=float32)}
episode index:667
target Thresh 31.971587867977437
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.1968698001288595
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9998665, 0.       ], dtype=float32)}
episode index:668
target Thresh 31.971870573414602
target distance 2.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
done in step count: 0
reward sum = 1.0
running average episode reward sum: 0.19807029370116314
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:669
target Thresh 31.97215046588567
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.1984885423672808
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9945779, 1.       ], dtype=float32)}
episode index:670
target Thresh 31.972427573380113
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.19861364071916415
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.24378729,  0.        ], dtype=float32)}
episode index:671
target Thresh 31.97270192360892
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 26.], dtype=float32)}
done in step count: 14
reward sum = -0.7712320754503899
running average episode reward sum: 0.19717041792724516
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.053617 , 1.2793401], dtype=float32)}
episode index:672
target Thresh 31.97297354400734
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.1972971030959729
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.56089306, -0.99991333], dtype=float32)}
episode index:673
target Thresh 31.973242461737637
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.19742341234431862
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.1920929e-06,  1.0000000e+00], dtype=float32)}
episode index:674
target Thresh 31.97350870369181
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  1.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.19759583780171966
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0001028], dtype=float32)}
episode index:675
target Thresh 31.97377229649428
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.1980896915919538
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  0.], dtype=float32)}
episode index:676
target Thresh 31.974033266504538
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  7.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.19850358702534826
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.9993495], dtype=float32)}
episode index:677
target Thresh 31.974291639819807
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 2.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.19917850798843773
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.47226202], dtype=float32)}
episode index:678
target Thresh 31.974547442277636
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 20.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.19930111627782296
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.2002047], dtype=float32)}
episode index:679
target Thresh 31.974800699458484
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 18.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.19942336395459234
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.55350935], dtype=float32)}
episode index:680
target Thresh 31.975051436688275
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.19991090820722876
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.6134341,  0.       ], dtype=float32)}
episode index:681
target Thresh 31.975299679040948
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.19852421564802886
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000000e+00,  1.1920929e-07], dtype=float32)}
episode index:682
target Thresh 31.97554545134094
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  5.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.19893383890476674
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0009577], dtype=float32)}
episode index:683
target Thresh 31.975788778165686
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.19910178738018375
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:684
target Thresh 31.976029683848072
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.19987536141320542
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99995077], dtype=float32)}
episode index:685
target Thresh 31.97626819247887
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.20044477050735524
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7.29084e-04, 1.00000e+00], dtype=float32)}
episode index:686
target Thresh 31.976504327909137
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  7.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.20071693312524844
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.99277127], dtype=float32)}
episode index:687
target Thresh 31.976738113752617
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.20088131344932514
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9579767,  1.       ], dtype=float32)}
episode index:688
target Thresh 31.976969573388086
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2014467832411258
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0535984, 0.       ], dtype=float32)}
episode index:689
target Thresh 31.977198729961703
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 27.], dtype=float32)}
done in step count: 14
reward sum = -0.7712320754503899
running average episode reward sum: 0.20003710373577577
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.5474949, -0.9999608], dtype=float32)}
episode index:690
target Thresh 31.977425606389314
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15.,  1.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2004397951920192
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99844074], dtype=float32)}
episode index:691
target Thresh 31.97765022535875
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 12.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.20091812063249317
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-5.9917760e-01,  1.1920929e-07], dtype=float32)}
episode index:692
target Thresh 31.9778726093321
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.20103574172318367
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99945354, 0.        ], dtype=float32)}
episode index:693
target Thresh 31.978092780547943
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2011982415133376
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9884412,  1.       ], dtype=float32)}
episode index:694
target Thresh 31.978310761023586
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.20141044323792273
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999987e+00, 1.5497208e-06], dtype=float32)}
episode index:695
target Thresh 31.978526572557254
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  4.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.20173954778786823
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.4744631], dtype=float32)}
episode index:696
target Thresh 31.978740236730285
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  0.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2022972959259057
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -1.639631], dtype=float32)}
episode index:697
target Thresh 31.978951774909273
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 25.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.2023716358784945
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.00446248, -0.9999896 ], dtype=float32)}
episode index:698
target Thresh 31.979161208248208
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  0.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.20248616792513616
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -1.611305], dtype=float32)}
episode index:699
target Thresh 31.979368557690606
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 0.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.20348261625667166
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.53883094], dtype=float32)}
episode index:700
target Thresh 31.97957384397158
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.20364000281848813
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999607, 1.       ], dtype=float32)}
episode index:701
target Thresh 31.979777087619926
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.000039, 26.      ], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.20228750506922089
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.6312141e-01,  1.1920929e-07], dtype=float32)}
episode index:702
target Thresh 31.979978308960185
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 11.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.20275571772203851
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99986565], dtype=float32)}
episode index:703
target Thresh 31.980177528114655
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.20307917154629695
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:704
target Thresh 31.980374765005415
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.20328569533147953
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:705
target Thresh 31.980570039356323
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6.999563, 6.      ], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.20403033315678906
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9995632, 0.       ], dtype=float32)}
episode index:706
target Thresh 31.980763370694977
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 7.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.20466975277042868
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99995947], dtype=float32)}
episode index:707
target Thresh 31.980954778354665
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.20505623179193938
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.7963419, 0.       ], dtype=float32)}
episode index:708
target Thresh 31.981144281476322
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  5.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.20516536198190985
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.014604], dtype=float32)}
episode index:709
target Thresh 31.98133189901041
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 25.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.20523440595493941
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9999838], dtype=float32)}
episode index:710
target Thresh 31.981517649718842
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 12.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.20549064517159912
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.7335633], dtype=float32)}
episode index:711
target Thresh 31.981701552176848
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 25.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.20555903834247172
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.039238  , -0.99995697], dtype=float32)}
episode index:712
target Thresh 31.98188362477482
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 11.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.20601609579220176
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9999598], dtype=float32)}
episode index:713
target Thresh 31.982063885720173
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.20639744145635835
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:714
target Thresh 31.98224235303915
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.20650378005079842
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.6575904, 0.       ], dtype=float32)}
episode index:715
target Thresh 31.982419044578634
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 1.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.20713170773229173
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.      , 1.000169], dtype=float32)}
episode index:716
target Thresh 31.982593978007927
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2073291229796665
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9999896], dtype=float32)}
episode index:717
target Thresh 31.982767170820512
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2074774258670068
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:718
target Thresh 31.98293864033582
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2077276943831862
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99307823, 1.        ], dtype=float32)}
episode index:719
target Thresh 31.983108403700946
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.20825930869654286
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9988856, 1.       ], dtype=float32)}
episode index:720
target Thresh 31.983276477892364
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.20863384072331603
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99940157, 0.        ], dtype=float32)}
episode index:721
target Thresh 31.983442879717632
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 16.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.20888146765998733
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.36635017, 1.8345703 ], dtype=float32)}
episode index:722
target Thresh 31.98360762581708
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 18.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.20907482446834144
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.01864815, 0.9589758 ], dtype=float32)}
episode index:723
target Thresh 31.983770732665445
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.20775591805724275
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.08197594, 1.        ], dtype=float32)}
episode index:724
target Thresh 31.983932216573553
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2079502939497155
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2635169e+00, 3.6954880e-06], dtype=float32)}
episode index:725
target Thresh 31.984092093689927
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 27.], dtype=float32)}
done in step count: 14
reward sum = -0.7712320754503899
running average episode reward sum: 0.20660155790370985
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.01166868, -0.99983597], dtype=float32)}
episode index:726
target Thresh 31.984250380002415
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.20690948864937186
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:727
target Thresh 31.98440709133978
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.20728227355507328
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9991702e+00, 8.3446503e-07], dtype=float32)}
episode index:728
target Thresh 31.984562243373283
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 0.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.20810904684237772
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.8179301], dtype=float32)}
episode index:729
target Thresh 31.984715851618258
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 3.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.20905684266862104
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999998, 1.       ], dtype=float32)}
episode index:730
target Thresh 31.98486793143566
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.20775059060318227
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9875604e+00, 4.7683716e-07], dtype=float32)}
episode index:731
target Thresh 31.985018498033593
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.20805484827995385
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0162045, 1.       ], dtype=float32)}
episode index:732
target Thresh 31.985167566468846
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  3.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.20819912624422407
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.12560654], dtype=float32)}
episode index:733
target Thresh 31.985315151648383
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  5.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.20839051495519922
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.34250343], dtype=float32)}
episode index:734
target Thresh 31.98546126833085
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 11.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.20875773452668878
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.9989337], dtype=float32)}
episode index:735
target Thresh 31.985605931128035
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.2090589702270601
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:736
target Thresh 31.985749154506337
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.209576515722003
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  0.], dtype=float32)}
episode index:737
target Thresh 31.985890952788214
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.20971775431328757
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.70709205,  0.        ], dtype=float32)}
episode index:738
target Thresh 31.986031340153612
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2100811902343792
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999866, 1.       ], dtype=float32)}
episode index:739
target Thresh 31.986170330641386
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 1.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.21089189132865707
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.99967885], dtype=float32)}
episode index:740
target Thresh 31.9863079381507
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.21118821429582485
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2842882e+00, 4.7683716e-07], dtype=float32)}
episode index:741
target Thresh 31.986444176442415
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 17.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.21137351109610003
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.9972334], dtype=float32)}
episode index:742
target Thresh 31.986579059140478
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  5.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2118837620905871
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0569017], dtype=float32)}
episode index:743
target Thresh 31.986712599733274
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 2., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.21206762590511588
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-7.9521942e-01,  4.7683716e-07], dtype=float32)}
episode index:744
target Thresh 31.98684481157497
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 10.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2122509961255117
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.1297829], dtype=float32)}
episode index:745
target Thresh 31.98697570788686
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.1384435, 22.       ], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.21238713499945874
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.3998804e+00,  1.1920929e-07], dtype=float32)}
episode index:746
target Thresh 31.987105301758685
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 10.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.21281424860722387
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.11593437], dtype=float32)}
episode index:747
target Thresh 31.98723360614994
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  7.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.21331916271336393
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.9997901], dtype=float32)}
episode index:748
target Thresh 31.98736063389117
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  0.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.21374389146808573
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.5998843], dtype=float32)}
episode index:749
target Thresh 31.98748639768526
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.21383547232810296
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0271924,  1.       ], dtype=float32)}
episode index:750
target Thresh 31.98761091010869
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 8.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.21442437316388446
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000000e+00,  1.1920929e-07], dtype=float32)}
episode index:751
target Thresh 31.987734183612805
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2146029025082144
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0207169, 1.       ], dtype=float32)}
episode index:752
target Thresh 31.987856230525058
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 15.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.21473465243328982
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0052756], dtype=float32)}
episode index:753
target Thresh 31.987977063050245
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.21346071600145905
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-4.7683716e-07,  1.0000000e+00], dtype=float32)}
episode index:754
target Thresh 31.988096693271718
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 24.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.21351465754693114
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00375628, 0.6033729 ], dtype=float32)}
episode index:755
target Thresh 31.9882151331526
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.21360581479419843
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:756
target Thresh 31.988332394536975
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.21378424626752182
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.02166224,  1.        ], dtype=float32)}
episode index:757
target Thresh 31.988448489151082
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7.0010324, 19.       ], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2140133178278549
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0037222, 1.       ], dtype=float32)}
episode index:758
target Thresh 31.988563428604476
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.21410345777337947
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0001433e+00,  1.1920929e-07], dtype=float32)}
episode index:759
target Thresh 31.988677224391203
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.21445108072367766
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:760
target Thresh 31.98878988789093
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 20.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.21458164513283184
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.7395632], dtype=float32)}
episode index:761
target Thresh 31.988901430370106
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 4.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.21525673483738195
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.     , 0.53177], dtype=float32)}
episode index:762
target Thresh 31.98901186298307
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.21615417030941683
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 0.], dtype=float32)}
episode index:763
target Thresh 31.989121196773176
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.21649728906555635
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99999833,  0.        ], dtype=float32)}
episode index:764
target Thresh 31.989229442673892
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  5.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.21698616842625496
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0002757], dtype=float32)}
episode index:765
target Thresh 31.989336611509902
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  2.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2174737713395366
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.4678463], dtype=float32)}
episode index:766
target Thresh 31.989442713998177
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.21775146813048893
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999003, 1.       ], dtype=float32)}
episode index:767
target Thresh 31.98954776074905
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.21787654512001955
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.447298, 0.      ], dtype=float32)}
episode index:768
target Thresh 31.98965176226729
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.21662337221717543
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.4347906, 0.       ], dtype=float32)}
episode index:769
target Thresh 31.989754728953134
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  7.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.21710891329221804
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.9999306], dtype=float32)}
episode index:770
target Thresh 31.989856671103336
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  4.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.21759319485733838
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.8961065], dtype=float32)}
episode index:771
target Thresh 31.989957598912195
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.21825563890545066
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9006608, 1.       ], dtype=float32)}
episode index:772
target Thresh 31.990057522472576
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  2.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.21853016875162729
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.2210138], dtype=float32)}
episode index:773
target Thresh 31.99015645177692
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 13.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.21874837329975177
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9994192], dtype=float32)}
episode index:774
target Thresh 31.990254396718235
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  9.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.21915184765678436
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0001698], dtype=float32)}
episode index:775
target Thresh 31.990351367091105
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.2197149251726906
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9998541, 1.       ], dtype=float32)}
episode index:776
target Thresh 31.99044737259264
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.21998616363450177
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9996157, 1.       ], dtype=float32)}
episode index:777
target Thresh 31.990542422823477
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 22.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.2200664250391888
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5.636215e-04, -8.896938e-01], dtype=float32)}
episode index:778
target Thresh 31.990636527288714
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.220719741566738
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.98997116, 1.        ], dtype=float32)}
episode index:779
target Thresh 31.990729695398876
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22079885668842295
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.02126646, -0.9999813 ], dtype=float32)}
episode index:780
target Thresh 31.99082193647085
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.22135622050828413
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:781
target Thresh 31.990913259728828
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  5.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.22151903664586947
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.81988776], dtype=float32)}
episode index:782
target Thresh 31.991003674305205
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.22028361844176603
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0024519e+00,  1.1920929e-07], dtype=float32)}
episode index:783
target Thresh 31.991093189241514
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  2.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2204029130561133
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.5273099], dtype=float32)}
episode index:784
target Thresh 31.991181813489327
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 19.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.22056632137081886
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.9772711 , -0.99998236], dtype=float32)}
episode index:785
target Thresh 31.99126955591114
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22064502775136619
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.8596287, 0.       ], dtype=float32)}
episode index:786
target Thresh 31.991356425281268
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  8.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.22076340839728567
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.5555261], dtype=float32)}
episode index:787
target Thresh 31.991442430286718
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2209257371177206
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.5978161], dtype=float32)}
episode index:788
target Thresh 31.991527579528068
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  9.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.22104346190729257
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0169127], dtype=float32)}
episode index:789
target Thresh 31.991611881520313
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.22168644486690361
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99997187], dtype=float32)}
episode index:790
target Thresh 31.991695344693717
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.22201085757882913
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999814, 0.       ], dtype=float32)}
episode index:791
target Thresh 31.99177797739467
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.2207888572319277
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.24246204, 1.        ], dtype=float32)}
episode index:792
target Thresh 31.99185978788651
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  3.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2209061608118244
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.9955187], dtype=float32)}
episode index:793
target Thresh 31.99194078435036
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.22117009160425283
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9319296, 0.       ], dtype=float32)}
episode index:794
target Thresh 31.99202097488592
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2213304794639959
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.3350873, 1.       ], dtype=float32)}
episode index:795
target Thresh 31.99210036751233
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 4.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.2220700140375336
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2.3841858e-07, 0.0000000e+00], dtype=float32)}
episode index:796
target Thresh 31.9921789701689
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  9.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2223915032294564
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0001239], dtype=float32)}
episode index:797
target Thresh 31.99225679071597
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.22265224972916883
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.5083909, 0.       ], dtype=float32)}
episode index:798
target Thresh 31.992333836935664
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2228099796295078
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:799
target Thresh 31.99241011653266
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 18.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2229673152050959
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.5250487], dtype=float32)}
episode index:800
target Thresh 31.992485637134983
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 22.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22304155018796223
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.8075403], dtype=float32)}
episode index:801
target Thresh 31.99256040629476
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 15.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.22330018567401214
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99991596], dtype=float32)}
episode index:802
target Thresh 31.992634431488966
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22337382122918897
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99986255], dtype=float32)}
episode index:803
target Thresh 31.992707720120183
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5., 3.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.22410345577989893
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99985516], dtype=float32)}
episode index:804
target Thresh 31.992780279517333
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 7.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.22464009744973756
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9998443], dtype=float32)}
episode index:805
target Thresh 31.992852116936422
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 17.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22471179650560763
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0023341], dtype=float32)}
episode index:806
target Thresh 31.992923239561247
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  6.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.22491341818156102
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.0043869], dtype=float32)}
episode index:807
target Thresh 31.99299365450413
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 13.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2250665927136383
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0000554], dtype=float32)}
episode index:808
target Thresh 31.993063368806624
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 11.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.2253204871725831
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -1.000021], dtype=float32)}
episode index:809
target Thresh 31.993132389440216
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 16.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2254727809416293
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.34048748], dtype=float32)}
episode index:810
target Thresh 31.993200723307034
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 11.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.2258500537148209
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.0000048, -0.9999933], dtype=float32)}
episode index:811
target Thresh 31.993268377240515
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([28., 22.], dtype=float32)}
done in step count: 14
reward sum = -1.6712320754503898
running average episode reward sum: 0.22351374567397705
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0824436], dtype=float32)}
episode index:812
target Thresh 31.99333535800611
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 9.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2239651309806511
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99998057], dtype=float32)}
episode index:813
target Thresh 31.99340167230195
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.22403695457463188
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:814
target Thresh 31.99346732675952
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 27.], dtype=float32)}
done in step count: 14
reward sum = -0.7712320754503899
running average episode reward sum: 0.22281576558073615
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9996731], dtype=float32)}
episode index:815
target Thresh 31.99353232794433
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.22343608939742643
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.25396883, 1.        ], dtype=float32)}
episode index:816
target Thresh 31.99359668235654
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.22388535978984084
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:817
target Thresh 31.993660396431647
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  9.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.22419637634266498
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9963825], dtype=float32)}
episode index:818
target Thresh 31.993723476541117
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.22464362130439555
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:819
target Thresh 31.99378592899301
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11.,  9.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.22508977542475603
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9997442], dtype=float32)}
episode index:820
target Thresh 31.993847760032622
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.22570355158136413
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:821
target Thresh 31.993908975843116
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 13.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.22590028751496344
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9990804], dtype=float32)}
episode index:822
target Thresh 31.993969582546114
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.,  5.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.22614884999671925
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0039171], dtype=float32)}
episode index:823
target Thresh 31.99402958620234
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8.000261, 10.      ], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.22659101158652903
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.4166079, 0.       ], dtype=float32)}
episode index:824
target Thresh 31.994088992812216
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  3.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.22678595640763627
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0005571], dtype=float32)}
episode index:825
target Thresh 31.99414780831644
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.22698042920738487
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:826
target Thresh 31.994206038596626
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 15.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.22722648335586446
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9997431], dtype=float32)}
episode index:827
target Thresh 31.99426368947584
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  7.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.22733105354032598
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0131214], dtype=float32)}
episode index:828
target Thresh 31.994320766719223
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.22747743156995165
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:829
target Thresh 31.994377276034545
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2279147961102288
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:830
target Thresh 31.994433223072782
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 1.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.22861525965281576
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0002947], dtype=float32)}
episode index:831
target Thresh 31.99448861342869
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.22905020525419456
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 1.1920929e-07], dtype=float32)}
episode index:832
target Thresh 31.994543452641345
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 4.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.2296503850798198
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.9849161], dtype=float32)}
episode index:833
target Thresh 31.99459774619472
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 2.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.23034624792744593
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.959726], dtype=float32)}
episode index:834
target Thresh 31.994651499518213
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  3.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2304462052306346
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.34328973], dtype=float32)}
episode index:835
target Thresh 31.994704717987197
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23068546480571758
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 2.3841858e-06], dtype=float32)}
episode index:836
target Thresh 31.994757406923572
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 25.], dtype=float32)}
done in step count: 13
reward sum = 0.2541865828329001
running average episode reward sum: 0.23071354260503318
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0161579, 1.5974939], dtype=float32)}
episode index:837
target Thresh 31.994809571596267
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 4.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.23122116367591025
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9999758,  0.0773797], dtype=float32)}
episode index:838
target Thresh 31.994861217221796
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.2318144638383943
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0000001], dtype=float32)}
episode index:839
target Thresh 31.994912348964768
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  5.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.23187471987725453
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.47197473], dtype=float32)}
episode index:840
target Thresh 31.994962971938392
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.23193483261994627
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0002704, 1.       ], dtype=float32)}
episode index:841
target Thresh 31.995013091205017
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 20.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.23203207224401998
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.9936477], dtype=float32)}
episode index:842
target Thresh 31.995062711776605
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 21.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2321290811691042
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99721503], dtype=float32)}
episode index:843
target Thresh 31.995111838615255
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.23222586021521902
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9680557, 1.       ], dtype=float32)}
episode index:844
target Thresh 31.995160476633696
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17.,  8.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23246046536289328
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.0000000e+00, -3.1483173e-04], dtype=float32)}
episode index:845
target Thresh 31.995208630695764
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.23130411325588382
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9999857e-01,  1.1920929e-07], dtype=float32)}
episode index:846
target Thresh 31.99525630561691
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 7.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.23189171170540462
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:847
target Thresh 31.995303506164664
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  5.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.23231458704537467
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9960135], dtype=float32)}
episode index:848
target Thresh 31.995350237059125
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 2.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.23289961108890192
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.02894866], dtype=float32)}
episode index:849
target Thresh 31.995396502973414
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 1.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.23348325860526795
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99737704], dtype=float32)}
episode index:850
target Thresh 31.995442308534162
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 19.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23366414841771768
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.415512e-04, 1.000000e+00], dtype=float32)}
episode index:851
target Thresh 31.995487658321967
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.       ,  1.0090783], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23379914171781424
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99999964,  0.0413965 ], dtype=float32)}
episode index:852
target Thresh 31.995532556871844
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.23447464096550732
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:853
target Thresh 31.995577008673685
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  8.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.23453079423894466
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.      , -0.226524], dtype=float32)}
episode index:854
target Thresh 31.99562101817271
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([2., 3.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.23530912079539035
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:855
target Thresh 31.9956645897699
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 15.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23553710921735835
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.31388474, -0.9245479 ], dtype=float32)}
episode index:856
target Thresh 31.995707727822452
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2359512899533941
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.9986267e-01, 1.3232231e-05], dtype=float32)}
episode index:857
target Thresh 31.995750436644215
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2360826735782736
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9973335, 1.       ], dtype=float32)}
episode index:858
target Thresh 31.9957927205061
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.23617316010040598
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.12915897,  1.        ], dtype=float32)}
episode index:859
target Thresh 31.995834583636526
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  9.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.23645469933284738
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0589867], dtype=float32)}
episode index:860
target Thresh 31.995876030221847
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 14.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23663003706765243
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 2.8133392e-05], dtype=float32)}
episode index:861
target Thresh 31.99591706440675
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23680496798636744
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.0000000e+00, 3.5762787e-07], dtype=float32)}
episode index:862
target Thresh 31.995957690294695
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  7.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23697949350318506
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0758828], dtype=float32)}
episode index:863
target Thresh 31.9959979119483
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.23703209771959458
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.42794454,  1.        ], dtype=float32)}
episode index:864
target Thresh 31.996037733389766
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.2358958601301302
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.0655508,  1.       ], dtype=float32)}
episode index:865
target Thresh 31.996077158601267
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23607083083321317
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.993443, 0.      ], dtype=float32)}
episode index:866
target Thresh 31.99611619152536
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9., 3.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.23655529354274812
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.0234146], dtype=float32)}
episode index:867
target Thresh 31.996154836065372
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.23542353235529437
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.85452414, 0.        ], dtype=float32)}
episode index:868
target Thresh 31.996193096085783
target distance 6.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 1.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.23608472506834927
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.99833894], dtype=float32)}
episode index:869
target Thresh 31.99623097541263
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  5.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.23617406514998335
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.17720044], dtype=float32)}
episode index:870
target Thresh 31.996268477833876
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  0.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.23651306277897302
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.02592897], dtype=float32)}
episode index:871
target Thresh 31.9963056070998
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2369189996335843
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:872
target Thresh 31.99634236692335
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.23697113083272223
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0595053,  0.       ], dtype=float32)}
episode index:873
target Thresh 31.996378760980548
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23719252222765044
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:874
target Thresh 31.996414792910826
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.23606908686834216
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.8221288, 1.       ], dtype=float32)}
episode index:875
target Thresh 31.996450466317405
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  6.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23619763635833263
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.      , -1.699213], dtype=float32)}
episode index:876
target Thresh 31.99648578476766
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  3.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23637006834538127
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.9910226], dtype=float32)}
episode index:877
target Thresh 31.996520751793465
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  4.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23654210754886032
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.7975035], dtype=float32)}
episode index:878
target Thresh 31.99655537089155
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23671375530932806
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0152721, 0.       ], dtype=float32)}
episode index:879
target Thresh 31.996589645523848
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23693392968965835
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.97884464, 1.        ], dtype=float32)}
episode index:880
target Thresh 31.996623579117863
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 14.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23715360424165646
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.66055244], dtype=float32)}
episode index:881
target Thresh 31.99665717506697
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([5.000006, 9.      ], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.23762860015521467
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.99982643, 1.        ], dtype=float32)}
episode index:882
target Thresh 31.996690436730802
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.23790115768618272
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:883
target Thresh 31.99672336743555
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  6.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.23795152915540765
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.81440043], dtype=float32)}
episode index:884
target Thresh 31.996755970474307
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  8.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23812042063545802
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.1973544], dtype=float32)}
episode index:885
target Thresh 31.99678824910741
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23824520395313808
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.7576398e+00, 2.2649765e-06], dtype=float32)}
episode index:886
target Thresh 31.99682020656275
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 9.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.23864232322714807
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.1920929e-06, -9.9972844e-01], dtype=float32)}
episode index:887
target Thresh 31.996851846036094
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2389122045072977
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99998736,  1.        ], dtype=float32)}
episode index:888
target Thresh 31.996883170691415
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6.99961, 10.     ], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.23930768009277878
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.9404669e-01, 1.1920929e-07], dtype=float32)}
episode index:889
target Thresh 31.99691418366121
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  9.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2393913912343487
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.46400368], dtype=float32)}
episode index:890
target Thresh 31.9969448880468
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.       ,  1.0000153], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2395575293912125
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -0.390728], dtype=float32)}
episode index:891
target Thresh 31.99697528691865
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2396798622507515
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99959695,  1.        ], dtype=float32)}
episode index:892
target Thresh 31.997005383316672
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23980192112852222
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9772812e+00, 1.3113022e-06], dtype=float32)}
episode index:893
target Thresh 31.997035180250528
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23992370694392656
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.7683716e-07, 1.0000000e+00], dtype=float32)}
episode index:894
target Thresh 31.99706468069994
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 14.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.2401366047127043
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.8765303], dtype=float32)}
episode index:895
target Thresh 31.997093887614977
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.23903621406328485
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.2652696e+00, 5.1259995e-06], dtype=float32)}
episode index:896
target Thresh 31.99712280391635
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  7.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23920163688930124
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.84826446], dtype=float32)}
episode index:897
target Thresh 31.99715143249572
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23932354869688555
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.7963067, 1.       ], dtype=float32)}
episode index:898
target Thresh 31.99717977621596
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 10.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.23948828389188342
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.4993525], dtype=float32)}
episode index:899
target Thresh 31.99720783791148
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20.,  1.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.23960960628767022
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0110879], dtype=float32)}
episode index:900
target Thresh 31.99723562038846
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.23982143492664063
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000582e+00,  2.3841858e-07], dtype=float32)}
episode index:901
target Thresh 31.997263126425175
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  6.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2399850702415778
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.01152277], dtype=float32)}
episode index:902
target Thresh 31.99729035877225
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 12.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.24024898145947196
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.9676759], dtype=float32)}
episode index:903
target Thresh 31.99731732015295
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.240708993648123
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0046992], dtype=float32)}
episode index:904
target Thresh 31.997344013263422
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 11.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24075509369545217
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.1303066], dtype=float32)}
episode index:905
target Thresh 31.99737044077301
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.       ,  2.0001144], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2408357289078082
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.08258724], dtype=float32)}
episode index:906
target Thresh 31.997396605324486
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23.,  5.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24088158757106418
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.        ,  0.44030106], dtype=float32)}
episode index:907
target Thresh 31.997422509534324
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 13.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2411430581794661
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.0013032, -0.9590106], dtype=float32)}
episode index:908
target Thresh 31.997448155992966
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 26.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.24005729748051496
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000000e+00,  2.3841858e-06], dtype=float32)}
episode index:909
target Thresh 31.997473547265084
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2403190992415254
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-6.9236755e-04,  3.6954880e-06], dtype=float32)}
episode index:910
target Thresh 31.99749868588982
target distance 13.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 11.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.24070348003269823
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.99616706,  1.        ], dtype=float32)}
episode index:911
target Thresh 31.997523574381063
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.24123889288353959
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9912398e+00, 3.2186508e-06], dtype=float32)}
episode index:912
target Thresh 31.99754821522768
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.24131837996262664
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-3.8051605e-04,  1.0000000e+00], dtype=float32)}
episode index:913
target Thresh 31.997572610893776
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.       , 1.0000076], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.24170040580511828
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.        ,  0.15112233], dtype=float32)}
episode index:914
target Thresh 31.997596763818937
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10.,  8.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.242081596618446
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.9978706], dtype=float32)}
episode index:915
target Thresh 31.997620676418478
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  9.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24212564458772828
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.6620612], dtype=float32)}
episode index:916
target Thresh 31.99764435108368
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  7.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.24244114661107863
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.52955294], dtype=float32)}
episode index:917
target Thresh 31.997667790182025
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14.,  5.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.2426980700897158
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.08052611], dtype=float32)}
episode index:918
target Thresh 31.997690996057447
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24274130345902079
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.80484843,  1.        ], dtype=float32)}
episode index:919
target Thresh 31.99771397103055
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.24305510747700013
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9384804, 1.       ], dtype=float32)}
episode index:920
target Thresh 31.997736717398848
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.24321185599114017
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9124875e+00, 1.4305115e-06], dtype=float32)}
episode index:921
target Thresh 31.997759237437002
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([16.      ,  4.985631], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.2434149529043819
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.2216065], dtype=float32)}
episode index:922
target Thresh 31.997781533397035
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2435289978525895
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.9999809e-01,  2.3841858e-07], dtype=float32)}
episode index:923
target Thresh 31.997803607508555
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 9., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.24378307566876634
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0002022e+00,  2.3841858e-07], dtype=float32)}
episode index:924
target Thresh 31.997825461978998
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24389647606274606
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-9.3997049e-01,  2.3841858e-07], dtype=float32)}
episode index:925
target Thresh 31.997847098993823
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.24409795633697634
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0518079, 1.       ], dtype=float32)}
episode index:926
target Thresh 31.997868520716757
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 2.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.24462104376271857
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.00047791], dtype=float32)}
episode index:927
target Thresh 31.997889729289987
target distance 4.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 2.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.24532727108625013
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.0000000e+00,  2.3841858e-07], dtype=float32)}
episode index:928
target Thresh 31.997910726834384
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2454385209990744
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:929
target Thresh 31.997931515449725
target distance 12.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 10.], dtype=float32)}
done in step count: 5
reward sum = 0.5904900000000001
running average episode reward sum: 0.2458095440947743
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.5522338e-01, 4.7683716e-07], dtype=float32)}
episode index:930
target Thresh 31.99795209721489
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  7.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.245961650372868
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.8466465], dtype=float32)}
episode index:931
target Thresh 31.997972474188067
target distance 5.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 3.], dtype=float32)}
done in step count: 1
reward sum = 0.9
running average episode reward sum: 0.246663408258734
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9999999, 1.       ], dtype=float32)}
episode index:932
target Thresh 31.997992648406974
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.24559966032151445
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.91230965, 1.        ], dtype=float32)}
episode index:933
target Thresh 31.998012621889046
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 17.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.24579759131688755
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 1.], dtype=float32)}
episode index:934
target Thresh 31.998032396631654
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  4.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24590762431023847
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.13529658], dtype=float32)}
episode index:935
target Thresh 31.998051974612284
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 21.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24594664344717307
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.99968195], dtype=float32)}
episode index:936
target Thresh 31.998071357788753
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 21.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.2459855792988634
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.        , 0.99942374], dtype=float32)}
episode index:937
target Thresh 31.998090548099395
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 7., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24609505996069828
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9901228,  0.       ], dtype=float32)}
episode index:938
target Thresh 31.998109547463255
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 15.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.24616717448266773
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.99580455], dtype=float32)}
episode index:939
target Thresh 31.998128357780285
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.24623913556948404
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9999604, 1.       ], dtype=float32)}
episode index:940
target Thresh 31.99814698093153
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  8.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.24638916888875131
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.7890525], dtype=float32)}
episode index:941
target Thresh 31.99816541877933
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24642742830233122
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.9847225, 1.       ], dtype=float32)}
episode index:942
target Thresh 31.998183673167475
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24653585991611454
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.3826017,  0.       ], dtype=float32)}
episode index:943
target Thresh 31.998201745921424
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24657388287857734
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.6994424, 0.       ], dtype=float32)}
episode index:944
target Thresh 31.998219638848468
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([23., 14.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.24664503283964764
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.00586522], dtype=float32)}
episode index:945
target Thresh 31.998237353737913
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 11.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.24683934803749155
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.64112425], dtype=float32)}
episode index:946
target Thresh 31.99825489236126
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24687693007386274
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00066423, 0.        ], dtype=float32)}
episode index:947
target Thresh 31.998272256472394
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.24702518277315189
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00048566, 0.        ], dtype=float32)}
episode index:948
target Thresh 31.998289447807732
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 0.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.24753305929288516
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5472178], dtype=float32)}
episode index:949
target Thresh 31.998306468086426
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  1.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24756979242676738
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.      , -1.673053], dtype=float32)}
episode index:950
target Thresh 31.998323319010517
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 24.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24760644830905365
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.9998457e+00,  2.3841858e-07], dtype=float32)}
episode index:951
target Thresh 31.99834000226511
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.24790459384654415
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.9932029, 1.       ], dtype=float32)}
episode index:952
target Thresh 31.99835651951855
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24801033765163696
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 1.], dtype=float32)}
episode index:953
target Thresh 31.998372872422568
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 14.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.24815646988575474
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.4207536], dtype=float32)}
episode index:954
target Thresh 31.998389062612475
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 13.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.24845310290158118
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.6622064,  1.       ], dtype=float32)}
episode index:955
target Thresh 31.9984050917073
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 16.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24855794112040797
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.474484], dtype=float32)}
episode index:956
target Thresh 31.998420961309968
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 8., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24866256024159877
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.33151293,  1.        ], dtype=float32)}
episode index:957
target Thresh 31.99843667300745
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([20., 15.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.24876696095126308
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.0000001], dtype=float32)}
episode index:958
target Thresh 31.99845222837093
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18., 17.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.24891154231523463
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -0.9999728], dtype=float32)}
episode index:959
target Thresh 31.998467628955957
target distance 7.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([3., 5.], dtype=float32)}
done in step count: 2
reward sum = 0.81
running average episode reward sum: 0.24949600945865627
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:960
target Thresh 31.998482876302607
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 11.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2495629341065557
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.0000329], dtype=float32)}
episode index:961
target Thresh 31.998497971935617
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([15., 11.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.24980070330187112
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0000017], dtype=float32)}
episode index:962
target Thresh 31.99851291736457
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  8.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.24986717255710283
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.6718518], dtype=float32)}
episode index:963
target Thresh 31.998527714084023
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 25.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.24990095094291603
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.7997985, 1.       ], dtype=float32)}
episode index:964
target Thresh 31.998542363573655
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([10., 23.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2499671785544674
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([9.300709e-04, 1.000000e+00], dtype=float32)}
episode index:965
target Thresh 31.99855686729843
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 5.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.25046307174436966
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.        , -0.99996924], dtype=float32)}
episode index:966
target Thresh 31.998571226708734
target distance 8.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([6., 0.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.25095793930202803
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.6637597], dtype=float32)}
episode index:967
target Thresh 31.998585443240515
target distance 19.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([17., 16.], dtype=float32)}
done in step count: 8
reward sum = 0.4304672100000001
running average episode reward sum: 0.25114338276349285
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:968
target Thresh 31.998599518315444
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 18.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2512840196120341
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:969
target Thresh 31.998613453341036
target distance 15.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13.,  7.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.2515728412413001
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99852276], dtype=float32)}
episode index:970
target Thresh 31.998627249710808
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  4.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.25160461950622254
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.10039723], dtype=float32)}
episode index:971
target Thresh 31.998640908804408
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([4.999999, 8.      ], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.25202076701701864
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000147e+00, 2.7418137e-06], dtype=float32)}
episode index:972
target Thresh 31.998654431987752
target distance 9.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([7., 6.], dtype=float32)}
done in step count: 3
reward sum = 0.7290000000000001
running average episode reward sum: 0.25251098205605566
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1., 0.], dtype=float32)}
episode index:973
target Thresh 31.998667820613175
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19.,  0.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.25264949284347243
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -1.7313619], dtype=float32)}
episode index:974
target Thresh 31.99868107601955
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  8.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.25271222218013556
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.8018031], dtype=float32)}
episode index:975
target Thresh 31.99869419953243
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 21.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.25281054822308624
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.6542665, 1.       ], dtype=float32)}
episode index:976
target Thresh 31.99870719246417
target distance 10.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([8., 5.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.2532233316947105
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.99982107], dtype=float32)}
episode index:977
target Thresh 31.998720056114085
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 14.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.25325319488978854
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.6542896], dtype=float32)}
episode index:978
target Thresh 31.99873279176854
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21., 12.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.25335066705037096
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 0.3188901], dtype=float32)}
episode index:979
target Thresh 31.998745400701118
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24.,  8.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.2533803393661165
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.        , 0.43496466], dtype=float32)}
episode index:980
target Thresh 31.99875788417272
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  1.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2534774831996882
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.0191944], dtype=float32)}
episode index:981
target Thresh 31.998770243431704
target distance 16.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([11., 14.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.25370642354266204
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.000000e+00, 4.172325e-06], dtype=float32)}
episode index:982
target Thresh 31.998782479714006
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 22.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2537675671566471
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.0000000e+00, 4.7683716e-06], dtype=float32)}
episode index:983
target Thresh 31.998794594243265
target distance 22.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 5., 20.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2538640212958172
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.5057296e+00, 2.3841858e-06], dtype=float32)}
episode index:984
target Thresh 31.998806588230945
target distance 23.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([21.,  5.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.2539602795890194
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.6333252], dtype=float32)}
episode index:985
target Thresh 31.998818462876454
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25., 23.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.25398915307471104
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.        , -0.99954164], dtype=float32)}
episode index:986
target Thresh 31.998830219367264
target distance 24.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22.,  9.], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.2540497624394682
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 0.8018223], dtype=float32)}
episode index:987
target Thresh 31.998841858879036
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([24., 17.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.2540784869071216
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.       , 1.1480768], dtype=float32)}
episode index:988
target Thresh 31.99885338257573
target distance 28.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4., 26.], dtype=float32)}
done in step count: 15
reward sum = -0.794108867905351
running average episode reward sum: 0.25301864125008167
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.6502352,  0.1875683], dtype=float32)}
episode index:989
target Thresh 31.99886479160973
target distance 20.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([18.,  6.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2531544006922533
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 0.       , -1.5402195], dtype=float32)}
episode index:990
target Thresh 31.998876087121943
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([14., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.25214636051277867
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.26545334,  1.        ], dtype=float32)}
episode index:991
target Thresh 31.99888727024193
target distance 17.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([13., 15.], dtype=float32)}
done in step count: 7
reward sum = 0.4782969000000001
running average episode reward sum: 0.25237433484693916
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.,  1.], dtype=float32)}
episode index:992
target Thresh 31.998898342088015
target distance 18.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 6., 16.], dtype=float32)}
done in step count: 10
reward sum = 0.3486784401000001
running average episode reward sum: 0.25247131783309534
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.716537,  0.372653], dtype=float32)}
episode index:993
target Thresh 31.99890930376739
target distance 26.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 24.], dtype=float32)}
done in step count: 14
reward sum = 0.2287679245496101
running average episode reward sum: 0.25244747136097917
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-1.7747297,  0.6512705], dtype=float32)}
episode index:994
target Thresh 31.998920156376233
target distance 27.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([25.,  2.], dtype=float32)}
done in step count: 12
reward sum = 0.2824295364810001
running average episode reward sum: 0.252477604089743
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([1.       , 1.6356115], dtype=float32)}
episode index:995
target Thresh 31.998930900999817
target distance 14.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([12.,  1.], dtype=float32)}
done in step count: 6
reward sum = 0.531441
running average episode reward sum: 0.2527576878205766
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.      , 1.000055], dtype=float32)}
episode index:996
target Thresh 31.998941538712607
target distance 29.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([22., 27.], dtype=float32)}
done in step count: 13
reward sum = -0.7458134171670999
running average episode reward sum: 0.2517561119880915
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00574696, 1.        ], dtype=float32)}
episode index:997
target Thresh 31.998952070578387
target distance 11.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0., 9.], dtype=float32)}
done in step count: 4
reward sum = 0.6561
running average episode reward sum: 0.25216126618449625
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([0.00242114, 1.        ], dtype=float32)}
episode index:998
target Thresh 31.99896249765035
target distance 25.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 4.9999986, 23.       ], dtype=float32)}
done in step count: 11
reward sum = 0.31381059609000006
running average episode reward sum: 0.25222297722544273
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([-0.9997374,  1.       ], dtype=float32)}
episode index:999
target Thresh 31.998972820971215
target distance 21.0
at step 0:
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([19., 17.], dtype=float32)}
done in step count: 9
reward sum = 0.3874204890000001
running average episode reward sum: 0.2523581747372173
{'currentTarget': array([0., 0.], dtype=float32), 'previousTarget': array([0., 0.], dtype=float32), 'currentState': array([ 1.       , -0.9999969], dtype=float32)}

Process finished with exit code 0
